<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kubernetes – Orquestração de contêineres prontos para produção</title><link>https://kubernetes.io/pt-br/</link><description>The Kubernetes project blog</description><generator>Hugo -- gohugo.io</generator><image><url>https://raw.githubusercontent.com/kubernetes/kubernetes/master/logo/logo.png</url><title>Kubernetes.io</title><link>https://kubernetes.io/pt-br/</link></image><atom:link href="https://kubernetes.io/pt-br/feed.xml" rel="self" type="application/rss+xml"/><item><title>Blog: Não entre em pânico: Kubernetes e Docker</title><link>https://kubernetes.io/pt-br/blog/2020/12/02/dont-panic-kubernetes-and-docker/</link><pubDate>Wed, 02 Dec 2020 00:00:00 +0000</pubDate><guid>https://kubernetes.io/pt-br/blog/2020/12/02/dont-panic-kubernetes-and-docker/</guid><description>
&lt;p>&lt;strong>Autores / Autoras&lt;/strong>: Jorge Castro, Duffie Cooley, Kat Cosgrove, Justin Garrison, Noah Kantrowitz, Bob Killen, Rey Lejano, Dan “POP” Papandrea, Jeffrey Sica, Davanum “Dims” Srinivas&lt;/p>
&lt;p>&lt;strong>Tradução:&lt;/strong> João Brito&lt;/p>
&lt;p>Kubernetes está &lt;a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#deprecation">deixando de usar Docker&lt;/a> como seu agente de execução após a versão v1.20.&lt;/p>
&lt;p>&lt;strong>Não entre em pânico. Não é tão dramático quanto parece.&lt;/strong>&lt;/p>
&lt;p>TL;DR Docker como um agente de execução primário está sendo deixado de lado em favor de agentes de execução que utilizam a Interface de Agente de Execução de Containers (Container Runtime Interface &amp;quot;CRI&amp;quot;) criada para o Kubernetes. As imagens criadas com o Docker continuarão a funcionar em seu cluster com os agentes atuais, como sempre estiveram.&lt;/p>
&lt;p>Se você é um usuário final de Kubernetes, quase nada mudará para você. Isso não significa a morte do Docker, e isso não significa que você não pode, ou não deva, usar ferramentas Docker em desenvolvimento mais. Docker ainda é uma ferramenta útil para a construção de containers, e as imagens resultantes de executar &lt;code>docker build&lt;/code> ainda rodarão em seu cluster Kubernetes.&lt;/p>
&lt;p>Se você está usando um Kubernetes gerenciado como GKE, EKS, ou AKS (que usa como &lt;a href="https://github.com/Azure/AKS/releases/tag/2020-11-16">padrão containerd&lt;/a>) você precisará ter certeza que seus nós estão usando um agente de execução de container suportado antes que o suporte ao Docker seja removido nas versões futuras do Kubernetes. Se você tem mudanças em seus nós, talvez você precise atualizá-los baseado em seu ambiente e necessidades do agente de execução.&lt;/p>
&lt;p>Se você está rodando seus próprios clusters, você também precisa fazer mudanças para evitar quebras em seu cluster. Na versão v1.20, você terá o aviso de alerta da perda de suporte ao Docker. Quando o suporte ao agente de execução do Docker for removido em uma versão futura (atualmente planejado para a versão 1.22 no final de 2021) do Kubernetes ele não será mais suportado e você precisará trocar para um dos outros agentes de execução de container compatível, como o containerd ou CRI-O. Mas tenha certeza que esse agente de execução escolhido tenha suporte às configurações do daemon do Docker usadas atualmente (Ex.: logs)&lt;/p>
&lt;h2 id="então-porque-a-confusão-e-toda-essa-turma-surtando">Então porque a confusão e toda essa turma surtando?&lt;/h2>
&lt;p>Estamos falando aqui de dois ambientes diferentes, e isso está criando essa confusão. Dentro do seu cluster Kubernetes, existe uma coisa chamada de agente de execução de container que é responsável por baixar e executar as imagens de seu container. Docker é a escolha popular para esse agente de execução (outras escolhas comuns incluem containerd e CRI-O), mas Docker não foi projetado para ser embutido no Kubernetes, e isso causa problemas.&lt;/p>
&lt;p>Se liga, o que chamamos de &amp;quot;Docker&amp;quot; não é exatamente uma coisa - é uma stack tecnológica inteira, e uma parte disso é chamado de &amp;quot;containerd&amp;quot;, que é o agente de execução de container de alto-nível por si só. Docker é legal e útil porque ele possui muitas melhorias de experiência do usuário e isso o torna realmente fácil para humanos interagirem com ele enquanto estão desenvolvendo, mas essas melhorias para o usuário não são necessárias para o Kubernetes, pois ele não é humano.&lt;/p>
&lt;p>Como resultado dessa camada de abstração amigável aos humanos, seu cluster Kubernetes precisa usar outra ferramenta chamada Dockershim para ter o que ele realmente precisa, que é o containerd. Isso não é muito bom, porque adiciona outra coisa a ser mantida e que pode quebrar. O que está atualmente acontecendo aqui é que o Dockershim está sendo removido do Kubelet assim que que a versão v1.23 for lançada, que remove o suporte ao Docker como agente de execução de container como resultado. Você deve estar pensando, mas se o containerd está incluso na stack do Docker, porque o Kubernetes precisa do Dockershim?&lt;/p>
&lt;p>Docker não é compatível com CRI, a &lt;a href="https://kubernetes.io/blog/2016/12/container-runtime-interface-cri-in-kubernetes/">Container Runtime Interface&lt;/a> (interface do agente de execução de container). Se fosse, nós não precisaríamos do shim, e isso não seria nenhum problema. Mas isso não é o fim do mundo, e você não precisa entrar em pânico - você só precisa mudar seu agente de execução de container do Docker para um outro suportado.&lt;/p>
&lt;p>Uma coisa a ser notada: Se você está contando com o socket do Docker (&lt;code>/var/run/docker.sock&lt;/code>) como parte do seu fluxo de trabalho em seu cluster hoje, mover para um agente de execução diferente acaba com sua habilidade de usá-lo. Esse modelo é conhecido como Docker em Docker. Existem diversas opções por aí para esse caso específico como o &lt;a href="https://github.com/GoogleContainerTools/kaniko">kaniko&lt;/a>, &lt;a href="https://github.com/genuinetools/img">img&lt;/a>, e &lt;a href="https://github.com/containers/buildah">buildah&lt;/a>.&lt;/p>
&lt;h2 id="o-que-essa-mudança-representa-para-os-desenvolvedores-ainda-escrevemos-dockerfiles-ainda-vamos-fazer-build-com-docker">O que essa mudança representa para os desenvolvedores? Ainda escrevemos Dockerfiles? Ainda vamos fazer build com Docker?&lt;/h2>
&lt;p>Essa mudança aborda um ambiente diferente do que a maioria das pessoas usa para interagir com Docker. A instalação do Docker que você está usando em desenvolvimento não tem relação com o agente de execução de Docker dentro de seu cluster Kubernetes. É confuso, dá pra entender.
Como desenvolvedor, Docker ainda é útil para você em todas as formas que era antes dessa mudança ser anunciada. A imagem que o Docker cria não é uma imagem específica para Docker e sim uma imagem que segue o padrão OCI (&lt;a href="https://opencontainers.org/">Open Container Initiative&lt;/a>).&lt;/p>
&lt;p>Qualquer imagem compatível com OCI, independente da ferramenta usada para construí-la será vista da mesma forma pelo Kubernetes. Ambos &lt;a href="https://containerd.io/">containerd&lt;/a> e &lt;a href="https://cri-o.io/">CRI-O&lt;/a> sabem como baixar e executá-las. Esse é o porque temos um padrão para containers.&lt;/p>
&lt;p>Então, essa mudança está chegando. Isso irá causar problemas para alguns, mas nada catastrófico, no geral é uma boa coisa. Dependendo de como você interage com o Kubernetes, isso tornará as coisas mais fáceis. Se isso ainda é confuso para você, tudo bem, tem muita coisa rolando aqui; Kubernetes tem um monte de partes móveis, e ninguém é 100% especialista nisso. Nós encorajamos toda e qualquer tipo de questão independente do nível de experiência ou de complexidade! Nosso objetivo é ter certeza que todos estão entendendo o máximo possível as mudanças que estão chegando. Esperamos que isso tenha respondido a maioria de suas questões e acalmado algumas ansiedades! ❤️&lt;/p>
&lt;p>Procurando mais respostas? Dê uma olhada em nosso apanhado de &lt;a href="https://kubernetes.io/blog/2020/12/02/dockershim-faq/">questões quanto ao desuso do Dockershim&lt;/a>.&lt;/p></description></item><item><title>Blog: Escalando a rede do Kubernetes com EndpointSlices</title><link>https://kubernetes.io/pt-br/blog/2020/09/02/scaling-kubernetes-networking-with-endpointslices/</link><pubDate>Wed, 02 Sep 2020 00:00:00 +0000</pubDate><guid>https://kubernetes.io/pt-br/blog/2020/09/02/scaling-kubernetes-networking-with-endpointslices/</guid><description>
&lt;p>&lt;strong>Autor:&lt;/strong> Rob Scott (Google)&lt;/p>
&lt;p>EndpointSlices é um novo tipo de API que provê uma alternativa escalável e extensível à API de Endpoints. EndpointSlices mantém o rastreio dos endereços IP, portas, informações de topologia e prontidão de Pods que compõem um serviço.&lt;/p>
&lt;p>No Kubernetes 1.19 essa funcionalidade está habilitada por padrão, com o kube-proxy lendo os &lt;a href="https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/">EndpointSlices&lt;/a> ao invés de Endpoints. Apesar de isso ser uma mudança praticamente transparente, resulta numa melhoria notável de escalabilidade em grandes clusters. Também permite a adição de novas funcionalidades em releases futuras do Kubernetes, como o &lt;a href="https://kubernetes.io/docs/concepts/services-networking/service-topology/">Roteamento baseado em topologia.&lt;/a>.&lt;/p>
&lt;h2 id="limitações-de-escalabilidade-da-api-de-endpoints">Limitações de escalabilidade da API de Endpoints&lt;/h2>
&lt;p>Na API de Endpoints, existia apenas um recurso de Endpoint por serviço (Service). Isso significa que
era necessário ser possível armazenar endereços IPs e portas para cada Pod que compunha o serviço correspondente. Isso resultava em recursos imensos de API. Para piorar, o kube-proxy rodava em cada um dos nós e observava qualquer alteração nos recursos de Endpoint. Mesmo que fosse uma simples mudança em um Endpoint, todo o objeto precisava ser enviado para cada uma das instâncias do kube-proxy.&lt;/p>
&lt;p>Outra limitação da API de Endpoints era que ela limitava o número de objetos que podiam ser associados a um &lt;em>Service&lt;/em>. O tamanho padrão de um objeto armazenado no etcd é 1.5MB. Em alguns casos, isso poderia limitar um Endpoint a 5,000 IPs de Pod. Isso não chega a ser um problema para a maioria dos usuários, mas torna-se um problema significativo para serviços que se aproximem desse tamanho.&lt;/p>
&lt;p>Para demonstrar o quão significante se torna esse problema em grande escala, vamos usar de um simples exemplo: Imagine um &lt;em>Service&lt;/em> que possua 5,000 Pods, e que possa causar o Endpoint a ter 1.5Mb . Se apenas um Endpoint nessa lista sofra uma alteração, todo o objeto de Endpoint precisará ser redistribuído para cada um dos nós do cluster. Em um cluster com 3.000 nós, essa atualização causará o envio de 4.5Gb de dados (1.5Mb de Endpoints * 3,000 nós) para todo o cluster. Isso é quase que o suficiente para encher um DVD, e acontecerá para cada mudança de Endpoint. Agora imagine uma atualização gradual em um &lt;em>Deployment&lt;/em> que resulte nos 5,000 Pods serem substituídos - isso é mais que 22Tb (ou 5,000 DVDs) de dados transferidos.&lt;/p>
&lt;h2 id="dividindo-os-endpoints-com-a-api-de-endpointslice">Dividindo os endpoints com a API de EndpointSlice&lt;/h2>
&lt;p>A API de EndpointSlice foi desenhada para resolver esse problema com um modelo similar de &lt;em>sharding&lt;/em>. Ao invés de rastrar todos os IPs dos Pods para um &lt;em>Service&lt;/em>, com um único recurso de Endpoint, nós dividimos eles em múltiplos EndpointSlices menores.&lt;/p>
&lt;p>Usemos por exemplo um serviço com 15 pods. Nós teríamos um único recurso de Endpoints referente a todos eles. Se o EndpointSlices for configurado para armazenar 5 &lt;em>endpoints&lt;/em> cada, nós teríamos 3 EndpointSlices diferentes:
&lt;img src="https://kubernetes.io/images/blog/2020-09-02-scaling-kubernetes-networking-endpointslices/endpoint-slices.png" alt="EndpointSlices">&lt;/p>
&lt;p>Por padrão, o EndpointSlices armazena um máximo de 100 &lt;em>endpoints&lt;/em> cada, podendo isso ser configurado com a flag &lt;code>--max-endpoints-per-slice&lt;/code> no kube-controller-manager.&lt;/p>
&lt;h2 id="endpointslices-provê-uma-melhoria-de-escalabilidade-em-10x">EndpointSlices provê uma melhoria de escalabilidade em 10x&lt;/h2>
&lt;p>Essa API melhora dramaticamente a escalabilidade da rede. Agora quando um Pod é adicionado ou removido, apenas 1 pequeno EndpointSlice necessita ser atualizado. Essa diferença começa a ser notada quando centenas ou milhares de Pods compõem um único &lt;em>Service&lt;/em>.&lt;/p>
&lt;p>Mais significativo, agora que todos os IPs de Pods para um &lt;em>Service&lt;/em> não precisam ser armazenados em um único recurso, nós não precisamos nos preocupar com o limite de tamanho para objetos armazendos no etcd. EndpointSlices já foram utilizados para escalar um serviço além de 100,000 endpoints de rede.&lt;/p>
&lt;p>Tudo isso é possível com uma melhoria significativa de performance feita no kube-proxy. Quando o EndpointSlices é usado em grande escala, muito menos dados serão transferidos para as atualizações de endpoints e o kube-proxy torna-se mais rápido para atualizar regras do iptables ou do ipvs. Além disso, os &lt;em>Services&lt;/em> podem escalar agora para pelo menos 10x mais além dos limites anteriores.&lt;/p>
&lt;h2 id="endpointslices-permitem-novas-funcionalidades">EndpointSlices permitem novas funcionalidades&lt;/h2>
&lt;p>Introduzido como uma funcionalidade alpha no Kubernetes v1.16, os EndpointSlices foram construídos para permitir algumas novas funcionalidades arrebatadoras em futuras versões do Kubernetes. Isso inclui serviços dual-stack, roteamento baseado em topologia e subconjuntos de &lt;em>endpoints&lt;/em>.&lt;/p>
&lt;p>Serviços Dual-stack são uma nova funcionalidade que foi desenvolvida juntamente com o EndpointSlices. Eles irão utilizar simultâneamente endereços IPv4 e IPv6 para serviços, e dependem do campo addressType do Endpointslices para conter esses novos tipos de endereço por família de IP.&lt;/p>
&lt;p>O roteamento baseado por topologia irá atualizar o kube-proxy para dar preferência no roteamento de requisições para a mesma região ou zona, utilizando-se de campos de topologia armazenados em cada endpoint dentro de um EndpointSlice. Como uma melhoria futura disso, estamos explorando o potencial de subconjuntos de endpoint. Isso irá permitir o kube-proxy apenas observar um subconjunto de EndpointSlices. Por exemplo, isso pode ser combinado com o roteamento baseado em topologia e assim, o kube-proxy precisará observar apenas EndpointSlices contendo &lt;em>endpoints&lt;/em> na mesma zona. Isso irá permitir uma outra melhoria significativa de escalabilidade.&lt;/p>
&lt;h2 id="o-que-isso-significa-para-a-api-de-endpoints">O que isso significa para a API de Endpoints?&lt;/h2>
&lt;p>Apesar da API de EndpointSlice prover uma alternativa nova e escalável à API de Endpoints, a API de Endpoints continuará a ser considerada uma funcionalidade estável. A mudança mais significativa para a API de Endpoints envolve começar a truncar Endpoints que podem causar problemas de escalabilidade.&lt;/p>
&lt;p>A API de Endpoints não será removida, mas muitas novas funcionalidades irão depender da nova API EndpointSlice. Para obter vantágem da funcionalidade e escalabilidade que os EndpointSlices provém, aplicações que hoje consomem a API de Endpoints devem considerar suportar EndpointSlices no futuro.&lt;/p></description></item></channel></rss>