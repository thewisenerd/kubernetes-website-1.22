<!doctype html><html lang=ja class=no-js>
<head>
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-JPP6RFM2BP"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-JPP6RFM2BP')</script>
<link rel=alternate hreflang=en href=https://kubernetes.io/docs/tasks/administer-cluster/>
<link rel=alternate hreflang=zh href=https://kubernetes.io/zh/docs/tasks/administer-cluster/>
<link rel=alternate hreflang=ko href=https://kubernetes.io/ko/docs/tasks/administer-cluster/>
<link rel=alternate hreflang=fr href=https://kubernetes.io/fr/docs/tasks/administer-cluster/>
<link rel=alternate hreflang=de href=https://kubernetes.io/de/docs/tasks/administer-cluster/>
<link rel=alternate hreflang=es href=https://kubernetes.io/es/docs/tasks/administer-cluster/>
<link rel=alternate hreflang=id href=https://kubernetes.io/id/docs/tasks/administer-cluster/>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.87.0">
<link rel=canonical type=text/html href=https://kubernetes.io/ja/docs/tasks/administer-cluster/>
<link rel="shortcut icon" type=image/png href=/images/favicon.png>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=manifest href=/manifest.webmanifest>
<link rel=apple-touch-icon href=/images/kubernetes-192x192.png>
<title>クラスターの管理 | Kubernetes</title><meta property="og:title" content="クラスターの管理">
<meta property="og:description" content="クラスターの管理のための一般的なタスクについて学びます。">
<meta property="og:type" content="website">
<meta property="og:url" content="https://kubernetes.io/ja/docs/tasks/administer-cluster/"><meta property="og:site_name" content="Kubernetes">
<meta itemprop=name content="クラスターの管理">
<meta itemprop=description content="クラスターの管理のための一般的なタスクについて学びます。"><meta name=twitter:card content="summary">
<meta name=twitter:title content="クラスターの管理">
<meta name=twitter:description content="クラスターの管理のための一般的なタスクについて学びます。">
<link href=/scss/main.css rel=stylesheet>
<script src=/js/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://kubernetes.io","logo":"https://kubernetes.io/images/favicon.png"}</script>
<meta name=theme-color content="#326ce5">
<link rel=stylesheet href=/css/feature-states.css>
<meta name=description content="クラスターの管理のための一般的なタスクについて学びます。">
<meta property="og:description" content="クラスターの管理のための一般的なタスクについて学びます。">
<meta name=twitter:description content="クラスターの管理のための一般的なタスクについて学びます。">
<meta property="og:url" content="https://kubernetes.io/ja/docs/tasks/administer-cluster/">
<meta property="og:title" content="クラスターの管理">
<meta name=twitter:title content="クラスターの管理">
<meta name=twitter:image content="https://kubernetes.io/images/favicon.png">
<meta name=twitter:image:alt content="Kubernetes">
<meta property="og:image" content="/images/kubernetes-horizontal-color.png">
<meta property="og:type" content="article">
<script src=/js/script.js></script>
</head>
<body class=td-section>
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" data-auto-burger=primary>
<a class=navbar-brand href=/ja/></a>
<div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar>
<ul class="navbar-nav mt-2 mt-lg-0">
<li class="nav-item mr-2 mb-lg-0">
<a class="nav-link active" href=/ja/docs/>ドキュメント</span></a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ja/training/>トレーニング</span></a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ja/partners/>パートナー</span></a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ja/community/>コミュニティ</span></a>
</li>
<li class="nav-item mr-2 mb-lg-0">
<a class=nav-link href=/ja/case-studies/>ケーススタディ</span></a>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
バージョン
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/releases>Release Information</a>
<a class=dropdown-item href=https://kubernetes.io/ja/docs/tasks/administer-cluster/>v1.26</a>
<a class=dropdown-item href=https://v1-25.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.25</a>
<a class=dropdown-item href=https://v1-24.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.24</a>
<a class=dropdown-item href=https://v1-23.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.23</a>
<a class=dropdown-item href=https://v1-22.docs.kubernetes.io/ja/docs/tasks/administer-cluster/>v1.22</a>
</div>
</li>
<li class="nav-item dropdown">
<a class="nav-link dropdown-toggle" href=# id=navbarDropdownMenuLink role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
日本語 Japanese
</a>
<div class="dropdown-menu dropdown-menu-right" aria-labelledby=navbarDropdownMenuLink>
<a class=dropdown-item href=/docs/tasks/administer-cluster/>English</a>
<a class=dropdown-item href=/zh/docs/tasks/administer-cluster/>中文 Chinese</a>
<a class=dropdown-item href=/ko/docs/tasks/administer-cluster/>한국어 Korean</a>
<a class=dropdown-item href=/fr/docs/tasks/administer-cluster/>Français</a>
<a class=dropdown-item href=/de/docs/tasks/administer-cluster/>Deutsch</a>
<a class=dropdown-item href=/es/docs/tasks/administer-cluster/>Español</a>
<a class=dropdown-item href=/id/docs/tasks/administer-cluster/>Bahasa Indonesia</a>
</div>
</li>
</ul>
</div>
<button id=hamburger onclick=kub.toggleMenu() data-auto-burger-exclude><div></div></button>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
</div>
<div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
</div>
<main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
これは、このセクションの複数ページの印刷可能なビューです。
<a href=# onclick="return print(),!1">印刷するには、ここをクリックしてください</a>.
</p><p>
<a href=/ja/docs/tasks/administer-cluster/>このページの通常のビューに戻る</a>.
</p>
</div>
<h1 class=title>クラスターの管理</h1>
<div class=lead>クラスターの管理のための一般的なタスクについて学びます。</div>
<ul>
<li>1: <a href=#pg-adb489b1ab985c9215657b0d4c6ae92b>Namespaceに対する最小および最大メモリー制約の構成</a></li>
<li>2: <a href=#pg-9133578f1e75663bb031e5a377ca896d>Windowsノードの追加</a></li>
<li>3: <a href=#pg-e805c7d8d4ad6195cb82dbbc843bfc29>Windowsノードのアップグレード</a></li>
<li>4: <a href=#pg-77351865caa548b0a06694b904dd881c>EndpointSliceの有効化</a></li>
<li>5: <a href=#pg-9ceed97f912df7289ed8872e290cfbad>KubernetesクラスターでNodeLocal DNSキャッシュを使用する</a></li>
<li>6: <a href=#pg-00733cc3747eb3f5fe1c9e0439262967>Serviceトポロジーを有効にする</a></li>
<li>7: <a href=#pg-ce4cd28c8feb9faa783e79b48af37961>クラウドコントローラーマネージャーの運用管理</a></li>
<li>8: <a href=#pg-9585dc0efb0450fd68728e7511754717>クラウドコントローラーマネージャーの開発</a></li>
<li>9: <a href=#pg-e1afcdac8d5e8458274b3c481c5ebcda>サービスディスカバリーにCoreDNSを使用する</a></li>
<li>10: <a href=#pg-a3790dfb57271d13517e549dffa805b9>ネットワークポリシーを宣言する</a></li>
<li>11: <a href=#pg-8060aed5bf1172fa62199a4c306a4cd1>ノードのトポロジー管理ポリシーを制御する</a></li>
<li>12: <a href=#pg-a8f6511197efcd7d0db80ade49620f9d>拡張リソースをNodeにアドバタイズする</a></li>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-adb489b1ab985c9215657b0d4c6ae92b>1 - Namespaceに対する最小および最大メモリー制約の構成</h1>
<p>このページでは、Namespaceで実行されるコンテナが使用するメモリーの最小値と最大値を設定する方法を説明します。
<a href=/docs/reference/generated/kubernetes-api/v1.22/#limitrange-v1-core>LimitRange</a> で最小値と最大値のメモリー値を指定します。
PodがLimitRangeによって課される制約を満たさない場合、そのNamespaceではPodを作成できません。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<p>クラスター内の各ノードには、少なくとも1GiBのメモリーが必要です。</p>
<h2 id=namespaceの作成>Namespaceの作成</h2>
<p>この演習で作成したリソースがクラスターの他の部分から分離されるように、Namespaceを作成します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl create namespace constraints-mem-example
</code></pre></div><h2 id=limitrangeとpodを作成>LimitRangeとPodを作成</h2>
<p>LimitRangeの設定ファイルです。</p>
<div class=highlight>
<div class=copy-code-icon style=text-align:right>
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints.yaml download=admin/resource/memory-constraints.yaml><code>admin/resource/memory-constraints.yaml</code>
</a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick="copyCode('admin-resource-memory-constraints-yaml')" title="Copy admin/resource/memory-constraints.yaml to clipboard">
</img>
</div>
<div class=includecode id=admin-resource-memory-constraints-yaml>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>LimitRange<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>mem-min-max-demo-lr<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>max</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>1Gi<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>min</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>500Mi<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>type</span>:<span style=color:#bbb> </span>Container<span style=color:#bbb>
</span></code></pre></div>
</div>
</div>
<p>LimitRangeを作成します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><p>LimitRangeの詳細情報を表示します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get limitrange mem-min-max-demo-lr --namespace<span style=color:#666>=</span>constraints-mem-example --output<span style=color:#666>=</span>yaml
</code></pre></div><p>出力されるのは、予想通りメモリー制約の最小値と最大値を示しています。
しかし、LimitRangeの設定ファイルでデフォルト値を指定していないにもかかわらず、
自動的に作成されていることに気づきます。</p>
<pre><code>  limits:
  - default:
      memory: 1Gi
    defaultRequest:
      memory: 1Gi
    max:
      memory: 1Gi
    min:
      memory: 500Mi
    type: Container
</code></pre><p>constraints-mem-exampleNamespaceにコンテナが作成されるたびに、
Kubernetesは以下の手順を実行するようになっています。</p>
<ul>
<li>
<p>コンテナが独自のメモリー要求と制限を指定しない場合は、デフォルトのメモリー要求と制限をコンテナに割り当てます。</p>
</li>
<li>
<p>コンテナに500MiB以上のメモリー要求があることを確認します。</p>
</li>
<li>
<p>コンテナのメモリー制限が1GiB以下であることを確認します。</p>
</li>
</ul>
<p>以下は、1つのコンテナを持つPodの設定ファイルです。設定ファイルのコンテナ(containers)では、600MiBのメモリー要求と800MiBのメモリー制限が指定されています。これらはLimitRangeによって課される最小と最大のメモリー制約を満たしています。</p>
<div class=highlight>
<div class=copy-code-icon style=text-align:right>
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod.yaml download=admin/resource/memory-constraints-pod.yaml><code>admin/resource/memory-constraints-pod.yaml</code>
</a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick="copyCode('admin-resource-memory-constraints-pod-yaml')" title="Copy admin/resource/memory-constraints-pod.yaml to clipboard">
</img>
</div>
<div class=includecode id=admin-resource-memory-constraints-pod-yaml>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-ctr<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;800Mi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;600Mi&#34;</span><span style=color:#bbb>
</span></code></pre></div>
</div>
</div>
<p>Podの作成</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><p>Podのコンテナが実行されていることを確認します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get pod constraints-mem-demo --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><p>Podの詳細情報を見ます</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get pod constraints-mem-demo --output<span style=color:#666>=</span>yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><p>出力は、コンテナが600MiBのメモリ要求と800MiBのメモリー制限になっていることを示しています。これらはLimitRangeによって課される制約を満たしています。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>     </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>800Mi<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span>600Mi<span style=color:#bbb>
</span></code></pre></div><p>Podを消します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl delete pod constraints-mem-demo --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><h2 id=最大メモリ制約を超えるpodの作成の試み>最大メモリ制約を超えるPodの作成の試み</h2>
<p>これは、1つのコンテナを持つPodの設定ファイルです。コンテナは800MiBのメモリー要求と1.5GiBのメモリー制限を指定しています。</p>
<div class=highlight>
<div class=copy-code-icon style=text-align:right>
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod-2.yaml download=admin/resource/memory-constraints-pod-2.yaml><code>admin/resource/memory-constraints-pod-2.yaml</code>
</a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick="copyCode('admin-resource-memory-constraints-pod-2-yaml')" title="Copy admin/resource/memory-constraints-pod-2.yaml to clipboard">
</img>
</div>
<div class=includecode id=admin-resource-memory-constraints-pod-2-yaml>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-2<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-2-ctr<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1.5Gi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;800Mi&#34;</span><span style=color:#bbb>
</span></code></pre></div>
</div>
</div>
<p>Podを作成してみます。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod-2.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><p>出力は、コンテナが大きすぎるメモリー制限を指定しているため、Podが作成されないことを示しています。</p>
<pre><code>Error from server (Forbidden): error when creating &quot;examples/admin/resource/memory-constraints-pod-2.yaml&quot;:
pods &quot;constraints-mem-demo-2&quot; is forbidden: maximum memory usage per Container is 1Gi, but limit is 1536Mi.
</code></pre><h2 id=最低限のメモリ要求を満たさないpodの作成の試み>最低限のメモリ要求を満たさないPodの作成の試み</h2>
<p>これは、1つのコンテナを持つPodの設定ファイルです。コンテナは100MiBのメモリー要求と800MiBのメモリー制限を指定しています。</p>
<div class=highlight>
<div class=copy-code-icon style=text-align:right>
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod-3.yaml download=admin/resource/memory-constraints-pod-3.yaml><code>admin/resource/memory-constraints-pod-3.yaml</code>
</a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick="copyCode('admin-resource-memory-constraints-pod-3-yaml')" title="Copy admin/resource/memory-constraints-pod-3.yaml to clipboard">
</img>
</div>
<div class=includecode id=admin-resource-memory-constraints-pod-3-yaml>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-3<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-3-ctr<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;800Mi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Mi&#34;</span><span style=color:#bbb>
</span></code></pre></div>
</div>
</div>
<p>Podを作成してみます。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod-3.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><p>出力は、コンテナが小さすぎるメモリー要求を指定しているため、Podが作成されないことを示しています。</p>
<pre><code>Error from server (Forbidden): error when creating &quot;examples/admin/resource/memory-constraints-pod-3.yaml&quot;:
pods &quot;constraints-mem-demo-3&quot; is forbidden: minimum memory usage per Container is 500Mi, but request is 100Mi.
</code></pre><h2 id=メモリ要求や制限を指定しないpodの作成>メモリ要求や制限を指定しないPodの作成</h2>
<p>これは、1つのコンテナを持つPodの設定ファイルです。コンテナはメモリー要求を指定しておらず、メモリー制限も指定していません。</p>
<div class=highlight>
<div class=copy-code-icon style=text-align:right>
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/resource/memory-constraints-pod-4.yaml download=admin/resource/memory-constraints-pod-4.yaml><code>admin/resource/memory-constraints-pod-4.yaml</code>
</a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick="copyCode('admin-resource-memory-constraints-pod-4-yaml')" title="Copy admin/resource/memory-constraints-pod-4.yaml to clipboard">
</img>
</div>
<div class=includecode id=admin-resource-memory-constraints-pod-4-yaml>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>Pod<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-4<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>constraints-mem-demo-4-ctr<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>
</span></code></pre></div>
</div>
</div>
<p>Podを作成します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl apply -f https://k8s.io/examples/admin/resource/memory-constraints-pod-4.yaml --namespace<span style=color:#666>=</span>constraints-mem-example
</code></pre></div><p>Podの詳細情報を見ます</p>
<pre><code>kubectl get pod constraints-mem-demo-4 --namespace=constraints-mem-example --output=yaml
</code></pre><p>出力を見ると、Podのコンテナのメモリ要求は1GiB、メモリー制限は1GiBであることがわかります。
コンテナはどのようにしてこれらの値を取得したのでしょうか？</p>
<pre><code>resources:
  limits:
    memory: 1Gi
  requests:
    memory: 1Gi
</code></pre><p>コンテナが独自のメモリー要求と制限を指定していなかったため、LimitRangeから与えられのです。
コンテナが独自のメモリー要求と制限を指定していなかったため、LimitRangeから<a href=/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/>デフォルトのメモリー要求と制限</a>が与えられたのです。</p>
<p>この時点で、コンテナは起動しているかもしれませんし、起動していないかもしれません。このタスクの前提条件は、ノードが少なくとも1GiBのメモリーを持っていることであることを思い出してください。それぞれのノードが1GiBのメモリーしか持っていない場合、どのノードにも1GiBのメモリー要求に対応するのに十分な割り当て可能なメモリーがありません。たまたま2GiBのメモリーを持つノードを使用しているのであれば、おそらく1GiBのメモリーリクエストに対応するのに十分なスペースを持っていることになります。</p>
<p>Podを削除します。</p>
<pre><code>kubectl delete pod constraints-mem-demo-4 --namespace=constraints-mem-example
</code></pre><h2 id=最小および最大メモリー制約の強制>最小および最大メモリー制約の強制</h2>
<p>LimitRangeによってNamespaceに課される最大および最小のメモリー制約は、Podが作成または更新されたときにのみ適用されます。LimitRangeを変更しても、以前に作成されたPodには影響しません。</p>
<h2 id=最小-最大メモリー制約の動機>最小・最大メモリー制約の動機</h2>
<p>クラスター管理者としては、Podが使用できるメモリー量に制限を課したいと思うかもしれません。</p>
<p>例:</p>
<ul>
<li>
<p>クラスター内の各ノードは2GBのメモリーを持っています。クラスタ内のどのノードもその要求をサポートできないため、2GB以上のメモリーを要求するPodは受け入れたくありません。</p>
</li>
<li>
<p>クラスターは運用部門と開発部門で共有されています。 本番用のワークロードでは最大8GBのメモリーを消費しますが、開発用のワークロードでは512MBに制限したいとします。本番用と開発用に別々のNamespaceを作成し、それぞれのNamespaceにメモリー制限を適用します。</p>
</li>
</ul>
<h2 id=クリーンアップ>クリーンアップ</h2>
<p>Namespaceを削除します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl delete namespace constraints-mem-example
</code></pre></div><h2 id=次の項目>次の項目</h2>
<h3 id=クラスター管理者向け>クラスター管理者向け</h3>
<ul>
<li>
<p><a href=/docs/tasks/administer-cluster/manage-resources/memory-default-namespace/>名前空間に対するデフォルトのメモリー要求と制限の構成</a></p>
</li>
<li>
<p><a href=/docs/tasks/administer-cluster/manage-resources/cpu-default-namespace/>名前空間に対するデフォルトのCPU要求と制限の構成</a></p>
</li>
<li>
<p><a href=/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/>名前空間に対する最小および最大CPU制約の構成</a></p>
</li>
<li>
<p><a href=/docs/tasks/administer-cluster/manage-resources/quota-memory-cpu-namespace/>名前空間に対するメモリーとCPUのクォータの構成</a></p>
</li>
<li>
<p><a href=/docs/tasks/administer-cluster/manage-resources/quota-pod-namespace/>名前空間に対するPodクォータの設定</a></p>
</li>
<li>
<p><a href=/docs/tasks/administer-cluster/quota-api-object/>APIオブジェクトのクォータの設定</a></p>
</li>
</ul>
<h3 id=アプリケーション開発者向け>アプリケーション開発者向け</h3>
<ul>
<li>
<p><a href=/docs/tasks/configure-pod-container/assign-memory-resource/>コンテナとPodへのメモリーリソースの割り当て</a></p>
</li>
<li>
<p><a href=/docs/tasks/configure-pod-container/assign-cpu-resource/>コンテナとPodへのCPUリソースの割り当て</a></p>
</li>
<li>
<p><a href=/docs/tasks/configure-pod-container/quality-service-pod/>PodのQoS(サービス品質)を設定</a></p>
</li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-9133578f1e75663bb031e5a377ca896d>2 - Windowsノードの追加</h1>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>
<p>Kubernetesを使用してLinuxノードとWindowsノードを混在させて実行できるため、Linuxで実行するPodとWindowsで実行するPodを混在させることができます。このページでは、Windowsノードをクラスターに登録する方法を示します。</p>
<h2 id=始める前に>始める前に</h2>
作業するKubernetesサーバーは次のバージョン以降のものである必要があります: 1.17.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
<ul>
<li>
<p>WindowsコンテナをホストするWindowsノードを構成するには、<a href=https://www.microsoft.com/en-us/cloud-platform/windows-server-pricing>Windows Server 2019ライセンス</a>(またはそれ以上)を取得します。
VXLAN/オーバーレイネットワークを使用している場合は、<a href=https://support.microsoft.com/help/4489899>KB4489899</a>もインストールされている必要があります。</p>
</li>
<li>
<p>コントロールプレーンにアクセスできるLinuxベースのKubernetes kubeadmクラスター(<a href=/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/>kubeadmを使用したシングルコントロールプレーンクラスターの作成</a>を参照)</p>
</li>
</ul>
<h2 id=目標>目標</h2>
<ul>
<li>Windowsノードをクラスターに登録する</li>
<li>LinuxとWindowsのPodとServiceが相互に通信できるようにネットワークを構成する</li>
</ul>
<h2 id=はじめに-クラスターへのwindowsノードの追加>はじめに: クラスターへのWindowsノードの追加</h2>
<h3 id=ネットワーク構成>ネットワーク構成</h3>
<p>LinuxベースのKubernetesコントロールプレーンノードを取得したら、ネットワーキングソリューションを選択できます。このガイドでは、簡単にするためにVXLANモードでのFlannelの使用について説明します。</p>
<h4 id=flannel構成>Flannel構成</h4>
<ol>
<li>
<p>FlannelのためにKubernetesコントロールプレーンを準備する</p>
<p>クラスター内のKubernetesコントロールプレーンでは、多少の準備が推奨されます。Flannelを使用する場合は、iptablesチェーンへのブリッジIPv4トラフィックを有効にすることをお勧めします。すべてのLinuxノードで次のコマンドを実行する必要があります:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sudo sysctl net.bridge.bridge-nf-call-iptables<span style=color:#666>=</span><span style=color:#666>1</span>
</code></pre></div></li>
<li>
<p>Linux用のFlannelをダウンロードして構成する</p>
<p>最新のFlannelマニフェストをダウンロード:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre></div><p>VNIを4096、ポートを4789に設定するために、flannelマニフェストの<code>net-conf.json</code>セクションを変更します。次のようになります:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span>net-conf.json:</span> <span>|</span>
    {
      <span style=color:green;font-weight:700>&#34;Network&#34;</span>: <span style=color:#b44>&#34;10.244.0.0/16&#34;</span>,
      <span style=color:green;font-weight:700>&#34;Backend&#34;</span>: {
        <span style=color:green;font-weight:700>&#34;Type&#34;</span>: <span style=color:#b44>&#34;vxlan&#34;</span>,
        <span style=color:green;font-weight:700>&#34;VNI&#34;</span> : <span style=color:#666>4096</span>,
        <span style=color:green;font-weight:700>&#34;Port&#34;</span>: <span style=color:#666>4789</span>
      }
    }
</code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> Linux上のFlannelがWindows上のFlannelと相互運用するには、VNIを4096およびポート4789に設定する必要があります。これらのフィールドの説明については、<a href=https://github.com/coreos/flannel/blob/master/Documentation/backends.md#vxlan>VXLANドキュメント</a>を参照してください。
</div>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> L2Bridge/Host-gatewayモードを使用するには、代わりに<code>Type</code>の値を<code>"host-gw"</code>に変更し、<code>VNI</code>と<code>Port</code>を省略します。
</div>
</li>
<li>
<p>Flannelマニフェストを適用して検証する</p>
<p>Flannelの構成を適用しましょう:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl apply -f kube-flannel.yml
</code></pre></div><p>数分後、Flannel Podネットワークがデプロイされていれば、すべてのPodが実行されていることがわかります。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get pods -n kube-system
</code></pre></div><p>出力結果には、実行中のLinux flannel DaemonSetが含まれているはずです:</p>
<pre><code>NAMESPACE     NAME                                      READY        STATUS    RESTARTS   AGE
...
kube-system   kube-flannel-ds-54954                     1/1          Running   0          1m
</code></pre></li>
<li>
<p>Windows Flannelとkube-proxy DaemonSetを追加する</p>
<p>これで、Windows互換バージョンのFlannelおよびkube-proxyを追加できます。
互換性のあるバージョンのkube-proxyを確実に入手するには、イメージのタグを置換する必要があります。
次の例は、Kubernetesv1.22.16の使用方法を示していますが、
独自のデプロイに合わせてバージョンを調整する必要があります。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style=color:#b44>&#39;s/VERSION/v1.22.16/g&#39;</span> | kubectl apply -f -
kubectl apply -f https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml
</code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> ホストゲートウェイを使用している場合は、代わりに <a href=https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml>https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-host-gw.yml</a> を使用してください。
</div>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> <p>Windowsノードでイーサネット(「Ethernet0 2」など)ではなく別のインターフェースを使用している場合は、次の行を変更する必要があります:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>wins <span style=color:#a2f>cli </span><span style=color:#a2f;font-weight:700>process</span> run --path /k/flannel/setup.exe --args <span style=color:#b44>&#34;--mode=overlay --interface=Ethernet&#34;</span>
</code></pre></div><p><code>flannel-host-gw.yml</code>または<code>flannel-overlay.yml</code>ファイルで、それに応じてインターフェースを指定します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=color:#080;font-style:italic># 例</span>
curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/flannel-overlay.yml | sed <span style=color:#b44>&#39;s/Ethernet/Ethernet0 2/g&#39;</span> | kubectl apply -f -
</code></pre></div>
</div>
</li>
</ol>
<h3 id=windowsワーカーノードの参加>Windowsワーカーノードの参加</h3>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> <code>Containers</code>機能をインストールし、Dockerをインストールする必要があります。
行うための指示としては、<a href=https://docs.mirantis.com/docker-enterprise/v3.1/dockeree-products/docker-engine-enterprise/dee-windows.html>Dockerエンジンのインストール - Windowsサーバー上のエンタープライズ</a>を利用できます。
</div>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> Windowsセクションのすべてのコードスニペットは、
Windowsワーカーノードの(管理者)権限を持つPowerShell環境で実行されます。
</div>
<ol>
<li>
<p>wins、kubelet、kubeadmをインストールします。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-PowerShell data-lang=PowerShell>curl.exe -LO https<span>:</span>//raw.githubusercontent.com/<span style=color:#a2f>kubernetes-sigs</span>/<span style=color:#a2f>sig-windows</span>-tools/master/kubeadm/scripts/PrepareNode.ps1
.\PrepareNode.ps1 -KubernetesVersion <span style=color:#a2f>
</code></pre></div></li>
<li>
<p><code>kubeadm</code>を実行してノードに参加します</p>
<p>コントロールプレーンホストで<code>kubeadm init</code>を実行したときに提供されたコマンドを使用します。
このコマンドがなくなった場合、またはトークンの有効期限が切れている場合は、<code>kubeadm token create --print-join-command</code>
(コントロールプレーンホスト上で)を実行して新しいトークンを生成します。</p>
</li>
</ol>
<h4 id=インストールの確認>インストールの確認</h4>
<p>次のコマンドを実行して、クラスター内のWindowsノードを表示できるようになります:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>kubectl get nodes -o wide
</code></pre></div><p>新しいノードが<code>NotReady</code>状態の場合は、flannelイメージがまだダウンロード中の可能性があります。
<code>kube-system</code>名前空間のflannel Podを確認することで、以前と同様に進行状況を確認できます:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl -n kube-system get pods -l <span style=color:#b8860b>app</span><span style=color:#666>=</span>flannel
</code></pre></div><p>flannel Podが実行されると、ノードは<code>Ready</code>状態になり、ワークロードを処理できるようになります。</p>
<h2 id=次の項目>次の項目</h2>
<ul>
<li><a href=/docs/tasks/administer-cluster/kubeadm/upgrading-windows-nodes>Windows kubeadmノードのアップグレード</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-e805c7d8d4ad6195cb82dbbc843bfc29>3 - Windowsノードのアップグレード</h1>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>
<p>このページでは、<a href=/docs/tasks/administer-cluster/kubeadm/adding-windows-nodes>kubeadmで作られた</a>Windowsノードをアップグレードする方法について説明します。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
作業するKubernetesサーバーは次のバージョン以降のものである必要があります: 1.17.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<ul>
<li><a href=/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade>残りのkubeadmクラスターをアップグレードするプロセス</a>を理解します。
Windowsノードをアップグレードする前にコントロールプレーンノードをアップグレードしたいと思うかもしれません。</li>
</ul>
<h2 id=ワーカーノードをアップグレード>ワーカーノードをアップグレード</h2>
<h3 id=kubeadmをアップグレード>kubeadmをアップグレード</h3>
<ol>
<li>
<p>Windowsノードから、kubeadmをアップグレードします。:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#080;font-style:italic># v1.22.16を目的のバージョンに置き換えます</span>
curl.exe -Lo C:\k\kubeadm.exe https<span>:</span>//dl.k8s.io/<span style=color:#a2f>/bin/windows/amd64/kubeadm.exe
</code></pre></div></li>
</ol>
<h3 id=ノードをドレインする>ノードをドレインする</h3>
<ol>
<li>
<p>Kubernetes APIにアクセスできるマシンから、
ノードをスケジュール不可としてマークして、ワークロードを削除することでノードのメンテナンスを準備します:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># &lt;node-to-drain&gt;をドレインするノードの名前に置き換えます</span>
kubectl drain &lt;node-to-drain&gt; --ignore-daemonsets
</code></pre></div><p>このような出力結果が表示されるはずです:</p>
<pre><code>node/ip-172-31-85-18 cordoned
node/ip-172-31-85-18 drained
</code></pre></li>
</ol>
<h3 id=kubeletの構成をアップグレード>kubeletの構成をアップグレード</h3>
<ol>
<li>
<p>Windowsノードから、次のコマンドを呼び出して新しいkubelet構成を同期します:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell>kubeadm upgrade node
</code></pre></div></li>
</ol>
<h3 id=kubeletをアップグレード>kubeletをアップグレード</h3>
<ol>
<li>
<p>Windowsノードから、kubeletをアップグレードして再起動します:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-powershell data-lang=powershell><span style=color:#a2f>stop-service</span> kubelet
curl.exe -Lo C:\k\kubelet.exe https<span>:</span>//dl.k8s.io/<span style=color:#a2f>/bin/windows/amd64/kubelet.exe
<span style=color:#a2f>restart-service</span> kubelet
</code></pre></div></li>
</ol>
<h3 id=ノードをオンライン状態に>ノードをオンライン状態に</h3>
<ol>
<li>
<p>Kubernetes APIにアクセスできるマシンから、
スケジュール可能としてマークして、ノードをオンラインに戻します:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=color:#080;font-style:italic># &lt;node-to-drain&gt;をノードの名前に置き換えます</span>
kubectl uncordon &lt;node-to-drain&gt;
</code></pre></div></li>
</ol>
<h3 id=kube-proxyをアップグレード>kube-proxyをアップグレード</h3>
<ol>
<li>
<p>Kubernetes APIにアクセスできるマシンから、次を実行します、
もう一度v1.22.16を目的のバージョンに置き換えます:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl -L https://github.com/kubernetes-sigs/sig-windows-tools/releases/latest/download/kube-proxy.yml | sed <span style=color:#b44>&#39;s/VERSION/v1.22.16/g&#39;</span> | kubectl apply -f -
</code></pre></div></li>
</ol>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-77351865caa548b0a06694b904dd881c>4 - EndpointSliceの有効化</h1>
<p>このページはKubernetesのEndpointSliceの有効化の概要を説明します。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<h2 id=概要>概要</h2>
<p>EndpointSliceは、KubernetesのEndpointsに対してスケーラブルで拡張可能な代替手段を提供します。Endpointsが提供する機能のベースの上に構築し、スケーラブルな方法で拡張します。Serviceが多数(100以上)のネットワークエンドポイントを持つ場合、それらは単一の大きなEndpointsリソースではなく、複数の小さなEndpointSliceに分割されます。</p>
<h2 id=endpointsliceの有効化>EndpointSliceの有効化</h2>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.17 [beta]</code>
</div>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> EndpointSliceは、最終的には既存のEndpointsを置き換える可能性がありますが、多くのKubernetesコンポーネントはまだ既存のEndpointsに依存しています。現時点ではEndpointSliceを有効化することは、Endpointsの置き換えではなく、クラスター内のEndpointsへの追加とみなされる必要があります。
</div>
<p>EndpoitSliceはベータ版の機能です。APIとEndpointSlice<a class=glossary-tooltip title=クラスターの状態をAPIサーバーから取得、見張る制御ループで、現在の状態を望ましい状態に移行するように更新します。 data-toggle=tooltip data-placement=top href=/docs/concepts/architecture/controller/ target=_blank aria-label=コントローラー>コントローラー</a>はデフォルトで有効です。<a class=glossary-tooltip title=kube-proxyはクラスター内の各Nodeで動作しているネットワークプロキシです。 data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-proxy/ target=_blank aria-label=kube-proxy>kube-proxy</a>はデフォルトでEndpointSliceではなくEndpointsを使用します。</p>
<p>スケーラビリティと性能向上のため、kube-proxy上で<code>EndpointSliceProxying</code><a href=/ja/docs/reference/command-line-tools-reference/feature-gates/>フィーチャーゲート</a>を有効にできます。この変更はデータソースをEndpointSliceに移します、これはkube-proxyとKubernetes API間のトラフィックの量を削減します。</p>
<h2 id=endpointsliceの使用>EndpointSliceの使用</h2>
<p>クラスター内でEndpointSliceを完全に有効にすると、各Endpointsリソースに対応するEndpointSliceリソースが表示されます。既存のEndpointsの機能をサポートすることに加えて、EndpointSliceはトポロジーなどの新しい情報を含みます。これらにより、クラスター内のネットワークエンドポイントのスケーラビリティと拡張性が大きく向上します。</p>
<h2 id=次の項目>次の項目</h2>
<ul>
<li><a href=/docs/concepts/services-networking/endpoint-slices/>EndpointSlice</a>を参照してください。</li>
<li><a href=/ja/docs/concepts/services-networking/connect-applications-service/>サービスとアプリケーションの接続</a>を参照してください。</li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-9ceed97f912df7289ed8872e290cfbad>5 - KubernetesクラスターでNodeLocal DNSキャッシュを使用する</h1>
<p>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.18 [stable]</code>
</div>
このページでは、KubernetesのNodeLocal DNSキャッシュの機能の概要について説明します。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<h2 id=イントロダクション>イントロダクション</h2>
<p>NodeLocal DNSキャッシュは、クラスターノード上でDNSキャッシュエージェントをDaemonSetで稼働させることで、クラスターのDNSパフォーマンスを向上させます。現在のアーキテクチャーにおいて、ClusterFirstのDNSモードでのPodは、DNSクエリー用にkube-dnsのService IPに疎通します。これにより、kube-proxyによって追加されたiptablesを介してkube-dns/CoreDNSのエンドポイントへ変換されます。この新しいアーキテクチャーによって、Podは同じノード上で稼働するDNSキャッシュエージェントに対して疎通し、それによってiptablesのDNATルールとコネクショントラッキングを回避します。ローカルのキャッシュエージェントはクラスターのホスト名(デフォルトではcluster.localというサフィックス)に対するキャッシュミスがあるときはkube-dnsサービスへ問い合わせます。</p>
<h2 id=動機>動機</h2>
<ul>
<li>
<p>現在のDNSアーキテクチャーでは、ローカルのkube-dns/CoreDNSがないとき、DNSへの秒間クエリー数が最も高いPodは他のノードへ疎通する可能性があります。ローカルでキャッシュを持つことにより、この状況におけるレイテンシーの改善に役立ちます。</p>
</li>
<li>
<p>iptables DNATとコネクショントラッキングをスキップすることは<a href=https://github.com/kubernetes/kubernetes/issues/56903>conntrackの競合</a>を減らし、UDPでのDNSエントリーがconntrackテーブルを満杯にすることを避けるのに役立ちます。</p>
</li>
<li>
<p>ローカルのキャッシュエージェントからkube-dnsサービスへの接続がTCPにアップグレードされます。タイムアウトをしなくてはならないUDPエントリーと比べ、TCPのconntrackエントリーはコネクションクローズ時に削除されます(<a href=https://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt>デフォルトの</a> <code>nf_conntrack_udp_timeout</code> は30秒です)。</p>
</li>
<li>
<p>DNSクエリーをUDPからTCPにアップグレードすることで、UDPパケットの欠損や、通常30秒(10秒のタイムアウトで3回再試行する)であるDNSのタイムアウトによるテイルレイテンシーを減少させます。NodeLocalキャッシュはUDPのDNSクエリーを待ち受けるため、アプリケーションを変更する必要はありません。</p>
</li>
<li>
<p>DNSクエリーに対するノードレベルのメトリクスと可視性を得られます。</p>
</li>
<li>
<p>DNSの不在応答のキャッシュも再度有効にされ、それによりkube-dnsサービスに対するクエリー数を減らします。</p>
</li>
</ul>
<h2 id=アーキテクチャー図>アーキテクチャー図</h2>
<p>この図はNodeLocal DNSキャッシュが有効にされた後にDNSクエリーがあったときの流れとなります。</p>
<figure>
<img src=/images/docs/nodelocaldns.svg alt="NodeLocal DNSCache flow"> <figcaption>
<h4>Nodelocal DNSCacheのフロー</h4><p>この図は、NodeLocal DNSキャッシュがDNSクエリーをどう扱うかを表したものです。</p>
</figcaption>
</figure>
<h2 id=設定>設定</h2>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> NodeLocal DNSキャッシュ用のローカルに待ち受けているIPアドレスは、169.254.20.0/16の範囲のIPか、既存のIPと衝突しないことが保証されている他のIPとなります。このドキュメントでは例として169.254.10を使用します。
</div>
<p>この機能は、下記の手順により有効化できます。</p>
<ul>
<li>
<p><a href=https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/nodelocaldns/nodelocaldns.yaml><code>nodelocaldns.yaml</code></a>と同様のマニフェストを用意し、<code>nodelocaldns.yaml</code>という名前で保存してください。</p>
</li>
<li>
<p>マニフェスト内の変数を正しい値に置き換えてください。</p>
<ul>
<li>
<p>kubedns=<code>kubectl get svc kube-dns -n kube-system -o jsonpath={.spec.clusterIP}</code></p>
</li>
<li>
<p>domain=<code>&lt;cluster-domain></code></p>
</li>
<li>
<p>localdns=<code>&lt;node-local-address></code></p>
</li>
</ul>
<p><code>&lt;cluster-domain></code>はデフォルトで"cluster.local"です。<code>&lt;node-local-address></code> はNodeLocal DNSキャッシュ用に確保されたローカルの待ち受けIPアドレスです。</p>
<ul>
<li>
<p>kube-proxyがIPTABLESモードで稼働中のとき:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>sed -i <span style=color:#b44>&#34;s/__PILLAR__LOCAL__DNS__/</span><span style=color:#b8860b>$localdns</span><span style=color:#b44>/g; s/__PILLAR__DNS__DOMAIN__/</span><span style=color:#b8860b>$domain</span><span style=color:#b44>/g; s/__PILLAR__DNS__SERVER__/</span><span style=color:#b8860b>$kubedns</span><span style=color:#b44>/g&#34;</span> nodelocaldns.yaml
</code></pre></div><p><code>__PILLAR__CLUSTER__DNS__</code>と<code>__PILLAR__UPSTREAM__SERVERS__</code>はnode-local-dnsというPodによって生成されます。
このモードでは、node-local-dns Podは<code>&lt;node-local-address></code>とkube-dnsのサービスIPの両方で待ち受けるため、PodはIPアドレスでもDNSレコードのルップアップができます。</p>
</li>
<li>
<p>kube-proxyがIPVSモードで稼働中のとき:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash> sed -i <span style=color:#b44>&#34;s/__PILLAR__LOCAL__DNS__/</span><span style=color:#b8860b>$localdns</span><span style=color:#b44>/g; s/__PILLAR__DNS__DOMAIN__/</span><span style=color:#b8860b>$domain</span><span style=color:#b44>/g; s/,__PILLAR__DNS__SERVER__//g; s/__PILLAR__CLUSTER__DNS__/</span><span style=color:#b8860b>$kubedns</span><span style=color:#b44>/g&#34;</span> nodelocaldns.yaml
</code></pre></div><p>このモードでは、node-local-dns Podは<code>&lt;node-local-address></code>上のみで待ち受けます。node-local-dnsのインターフェースはkube-dnsのクラスターIPをバインドしません。なぜならばIPVSロードバランシング用に使われているインターフェースは既にこのアドレスを使用しているためです。
<code>__PILLAR__UPSTREAM__SERVERS__</code> はnode-local-dns Podにより生成されます。</p>
</li>
</ul>
</li>
<li>
<p><code>kubectl create -f nodelocaldns.yaml</code>を実行してください。</p>
</li>
<li>
<p>kube-proxyをIPVSモードで使用しているとき、NodeLocal DNSキャッシュが待ち受けている<code>&lt;node-local-address></code>を使用するため、kubeletに対する<code>--cluster-dns</code>フラグを修正する必要があります。IPVSモード以外のとき、<code>--cluster-dns</code>フラグの値を修正する必要はありません。なぜならNodeLocal DNSキャッシュはkube-dnsのサービスIPと<code>&lt;node-local-address></code>の両方で待ち受けているためです。</p>
</li>
</ul>
<p>一度有効にすると、クラスターの各Node上で、kube-systemという名前空間でnode-local-dns Podが、稼働します。このPodは<a href=https://github.com/coredns/coredns>CoreDNS</a>をキャッシュモードで稼働させるため、異なるプラグインによって公開された全てのCoreDNSのメトリクスがNode単位で利用可能となります。</p>
<p><code>kubectl delete -f &lt;manifest></code>を実行してDaemonSetを削除することによって、この機能を無効にできます。また、kubeletの設定に対して行った全ての変更をリバートすべきです。</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-00733cc3747eb3f5fe1c9e0439262967>6 - Serviceトポロジーを有効にする</h1>
<p>このページでは、Kubernetes上でServiceトポロジーを有効にする方法の概要について説明します。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<h2 id=はじめに>はじめに</h2>
<p><em>Serviceトポロジー</em>は、クラスターのノードのトポロジーに基づいてトラフィックをルーティングできるようにする機能です。たとえば、あるServiceのトラフィックに対して、できるだけ同じノードや同じアベイラビリティゾーン上にあるエンドポイントを優先してルーティングするように指定できます。</p>
<h2 id=前提>前提</h2>
<p>トポロジーを考慮したServiceのルーティングを有効にするには、以下の前提を満たしている必要があります。</p>
<ul>
<li>Kubernetesバージョン1.17以降である</li>
<li><a class=glossary-tooltip title=kube-proxyはクラスター内の各Nodeで動作しているネットワークプロキシです。 data-toggle=tooltip data-placement=top href=/docs/reference/command-line-tools-reference/kube-proxy/ target=_blank aria-label=Kube-proxy>Kube-proxy</a>がiptableモードまたはIPVSモードで稼働している</li>
<li><a href=/docs/concepts/services-networking/endpoint-slices/>Endpoint Slice</a>を有効にしている</li>
</ul>
<h2 id=serviceトポロジーを有効にする>Serviceトポロジーを有効にする</h2>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.17 [alpha]</code>
</div>
<p>Serviceトポロジーを有効にするには、すべてのKubernetesコンポーネントで<code>ServiceTopology</code>と<code>EndpointSlice</code>フィーチャーゲートを有効にする必要があります。</p>
<pre><code>--feature-gates=&quot;ServiceTopology=true,EndpointSlice=true&quot;
</code></pre><h2 id=次の項目>次の項目</h2>
<ul>
<li><a href=/ja/docs/concepts/services-networking/service-topology>Serviceトポロジー</a>のコンセプトについて読む</li>
<li><a href=/docs/concepts/services-networking/endpoint-slices>Endpoint Slice</a>について読む</li>
<li><a href=/ja/docs/concepts/services-networking/connect-applications-service/>サービスとアプリケーションの接続</a>を読む</li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-ce4cd28c8feb9faa783e79b48af37961>7 - クラウドコントローラーマネージャーの運用管理</h1>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.11 [beta]</code>
</div>
<p>クラウドプロバイダーはKubernetesプロジェクトとは異なるペースで開発およびリリースされるため、プロバイダー固有のコードを<a class=glossary-tooltip title=サードパーティクラウドプロバイダーにKubernetewを結合するコントロールプレーンコンポーネント data-toggle=tooltip data-placement=top href=/ja/docs/concepts/architecture/cloud-controller/ target=_blank aria-label="`cloud-controller-manager`">`cloud-controller-manager`</a>バイナリに抽象化することでクラウドベンダーはKubernetesのコアのコードとは独立して開発が可能となりました。</p>
<p><code>cloud-controller-manager</code>は、<a href=https://github.com/kubernetes/cloud-provider/blob/master/cloud.go>cloudprovider.Interface</a>を満たす任意のクラウドプロバイダーと接続できます。下位互換性のためにKubernetesのコアプロジェクトで提供される<a href=https://github.com/kubernetes/kubernetes/tree/master/cmd/cloud-controller-manager>cloud-controller-manager</a>は<code>kube-controller-manager</code>と同じクラウドライブラリを使用します。Kubernetesのコアリポジトリですでにサポートされているクラウドプロバイダーは、Kubernetesリポジトリにあるcloud-controller-managerを使用してKubernetesのコアから移行することが期待されています。</p>
<h2 id=運用>運用</h2>
<h3 id=要件>要件</h3>
<p>すべてのクラウドには動作させるためにそれぞれのクラウドプロバイダーの統合を行う独自の要件があり、<code>kube-controller-manager</code>を実行する場合の要件とそれほど違わないようにする必要があります。一般的な経験則として、以下のものが必要です。</p>
<ul>
<li>クラウドの認証/認可: クラウドではAPIへのアクセスを許可するためにトークンまたはIAMルールが必要になる場合があります</li>
<li>kubernetesの認証/認可: cloud-controller-managerは、kubernetes apiserverと通信するためにRBACルールの設定を必要とする場合があります</li>
<li>高可用性: kube-controller-managerのように、リーダー選出を使用したクラウドコントローラーマネージャーの高可用性のセットアップが必要になる場合があります(デフォルトでオンになっています)。</li>
</ul>
<h3 id=cloud-controller-managerを動かす>cloud-controller-managerを動かす</h3>
<p>cloud-controller-managerを正常に実行するにはクラスター構成にいくつかの変更が必要です。</p>
<ul>
<li><code>kube-apiserver</code>と<code>kube-controller-manager</code>は**<code>--cloud-provider</code>フラグを指定してはいけません**。これによりクラウドコントローラーマネージャーによって実行されるクラウド固有のループが実行されなくなります。将来このフラグは非推奨になり削除される予定です。</li>
<li><code>kubelet</code>は<code>--cloud-provider=external</code>で実行する必要があります。これは作業をスケジュールする前にクラウドコントローラーマネージャーによって初期化する必要があることをkubeletが認識できるようにするためです。</li>
</ul>
<p>クラウドコントローラーマネージャーを使用するようにクラスターを設定するとクラスターの動作がいくつか変わることに注意してください。</p>
<ul>
<li><code>--cloud-provider=external</code>を指定したkubeletは、初期化時に<code>NoSchedule</code>の<code>node.cloudprovider.kubernetes.io/uninitialized</code>汚染を追加します。これによりノードは作業をスケジュールする前に外部のコントローラーからの2回目の初期化が必要であるとマークされます。クラウドコントローラーマネージャーが使用できない場合クラスター内の新しいノードはスケジュールできないままになることに注意してください。スケジューラーはリージョンやタイプ(高CPU、GPU、高メモリ、スポットインスタンスなど)などのノードに関するクラウド固有の情報を必要とする場合があるためこの汚染は重要です。</li>
<li>クラスター内のノードに関するクラウド情報はローカルメタデータを使用して取得されなくなりましたが、代わりにノード情報を取得するためのすべてのAPI呼び出しはクラウドコントローラーマネージャーを経由して行われるようになります。これはセキュリティを向上させるためにkubeletでクラウドAPIへのアクセスを制限できることを意味します。大規模なクラスターではクラスター内からクラウドのほとんどすべてのAPI呼び出しを行うため、クラウドコントローラーマネージャーがレートリミットに達するかどうかを検討する必要があります。</li>
</ul>
<p>クラウドコントローラーマネージャーは以下を実装できます。</p>
<ul>
<li>ノードコントローラー - クラウドAPIを使用してkubernetesノードを更新し、クラウドで削除されたkubernetesノードを削除します。</li>
<li>サービスコントローラー - タイプLoadBalancerのサービスに対応してクラウド上のロードバランサーを操作します。</li>
<li>ルートコントローラー - クラウド上でネットワークルートを設定します。</li>
<li>Kubernetesリポジトリの外部にあるプロバイダーを実行している場合はその他の機能の実装。</li>
</ul>
<h2 id=例>例</h2>
<p>現在Kubernetesのコアでサポートされているクラウドを使用していて、クラウドコントローラーマネージャーを利用する場合は、<a href=https://github.com/kubernetes/kubernetes/tree/master/cmd/cloud-controller-manager>kubernetesのコアのクラウドコントローラーマネージャー</a>を参照してください。</p>
<p>Kubernetesのコアリポジトリにないクラウドコントローラーマネージャーの場合、クラウドベンダーまたはsigリードが管理するリポジトリでプロジェクトを見つけることができます。</p>
<p>すでにKubernetesのコアリポジトリにあるプロバイダーの場合、クラスター内でデーモンセットとしてKubernetesリポジトリ内部のクラウドコントローラーマネージャーを実行できます。以下をガイドラインとして使用してください。</p>
<div class=highlight>
<div class=copy-code-icon style=text-align:right>
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/admin/cloud/ccm-example.yaml download=admin/cloud/ccm-example.yaml><code>admin/cloud/ccm-example.yaml</code>
</a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick="copyCode('admin-cloud-ccm-example-yaml')" title="Copy admin/cloud/ccm-example.yaml to clipboard">
</img>
</div>
<div class=includecode id=admin-cloud-ccm-example-yaml>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:#080;font-style:italic># This is an example of how to setup cloud-controller-manager as a Daemonset in your cluster.</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># It assumes that your masters can run pods and has the role node-role.kubernetes.io/master</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># Note that this Daemonset will not work straight out of the box for your cloud, this is</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#080;font-style:italic># meant to be a guideline.</span><span style=color:#bbb>
</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRoleBinding<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>system:cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>roleRef</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>apiGroup</span>:<span style=color:#bbb> </span>rbac.authorization.k8s.io<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ClusterRole<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cluster-admin<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>subjects</span>:<span style=color:#bbb>
</span><span style=color:#bbb></span>- <span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>ServiceAccount<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:#00f;font-weight:700>---</span><span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>apps/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>DaemonSet<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>namespace</span>:<span style=color:#bbb> </span>kube-system<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>selector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>template</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>labels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>k8s-app</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>serviceAccountName</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># for in-tree providers we use k8s.gcr.io/cloud-controller-manager</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># this can be replaced with any other image for out-of-tree providers</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>k8s.gcr.io/cloud-controller-manager:v1.8.0<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>command</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- /usr/local/bin/cloud-controller-manager<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- --cloud-provider=&lt;YOUR_CLOUD_PROVIDER&gt;  <span style=color:#bbb> </span><span style=color:#080;font-style:italic># Add your own cloud provider here!</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span>- --leader-elect=true<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- --use-service-account-credentials<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:#080;font-style:italic># these flags will vary for every cloud provider</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span>- --allocate-node-cidrs=true<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- --configure-cloud-routes=true<span style=color:#bbb>
</span><span style=color:#bbb>        </span>- --cluster-cidr=172.17.0.0/16<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>tolerations</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># this is required so CCM can bootstrap itself</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node.cloudprovider.kubernetes.io/uninitialized<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>value</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># this is to have the daemonset runnable on master nodes</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># the taint may vary depending on your cluster setup</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span>- <span style=color:green;font-weight:700>key</span>:<span style=color:#bbb> </span>node-role.kubernetes.io/master<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>effect</span>:<span style=color:#bbb> </span>NoSchedule<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># this is to restrict CCM to only run on master nodes</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:#080;font-style:italic># the node selector may vary depending on your cluster setup</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>nodeSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>node-role.kubernetes.io/master</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;&#34;</span><span style=color:#bbb>
</span></code></pre></div>
</div>
</div>
<h2 id=制限>制限</h2>
<p>クラウドコントローラーマネージャーの実行にはいくつかの制限があります。これらの制限は今後のリリースで対処されますが、本番のワークロードにおいてはこれらの制限を認識することが重要です。</p>
<h3 id=ボリュームのサポート>ボリュームのサポート</h3>
<p>ボリュームの統合にはkubeletとの調整も必要になるためクラウドコントローラーマネージャーは<code>kube-controller-manager</code>にあるボリュームコントローラーを実装しません。CSI(コンテナストレージインターフェイス)が進化してFlexボリュームプラグインの強力なサポートが追加されるにつれ、クラウドがボリュームと完全に統合できるようクラウドコントローラーマネージャーに必要なサポートが追加されます。Kubernetesリポジトリの外部にあるCSIボリュームプラグインの詳細については<a href=https://github.com/kubernetes/features/issues/178>こちら</a>をご覧ください。</p>
<h3 id=スケーラビリティ>スケーラビリティ</h3>
<p>cloud-controller-managerは、クラウドプロバイダーのAPIにクエリーを送信して、すべてのノードの情報を取得します。非常に大きなクラスターの場合、リソース要件やAPIレートリミットなどのボトルネックの可能性を考慮する必要があります。</p>
<h3 id=鶏と卵>鶏と卵</h3>
<p>クラウドコントローラーマネージャープロジェクトの目標はKubernetesのコアプロジェクトからクラウドに関する機能の開発を切り離すことです。残念ながら、Kubernetesプロジェクトの多くの面でクラウドプロバイダーの機能がKubernetesプロジェクトに緊密に結びついているという前提があります。そのため、この新しいアーキテクチャを採用するとクラウドプロバイダーの情報を要求する状況が発生する可能性がありますが、クラウドコントローラーマネージャーはクラウドプロバイダーへのリクエストが完了するまでその情報を返すことができない場合があります。</p>
<p>これの良い例は、KubeletのTLSブートストラップ機能です。TLSブートストラップはKubeletがすべてのアドレスタイプ(プライベート、パブリックなど)をクラウドプロバイダー(またはローカルメタデータサービス)に要求する能力を持っていると仮定していますが、クラウドコントローラーマネージャーは最初に初期化されない限りノードのアドレスタイプを設定できないためapiserverと通信するためにはkubeletにTLS証明書が必要です。</p>
<p>このイニシアチブが成熟するに連れ、今後のリリースでこれらの問題に対処するための変更が行われます。</p>
<h2 id=次の項目>次の項目</h2>
<p>独自のクラウドコントローラーマネージャーを構築および開発するには<a href=/ja/docs/tasks/administer-cluster/developing-cloud-controller-manager/>クラウドコントローラーマネージャーの開発</a>を参照してください。</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-9585dc0efb0450fd68728e7511754717>8 - クラウドコントローラーマネージャーの開発</h1>
<p><p>cloud-controller-managerは クラウド特有の制御ロジックを組み込むKubernetesの<a class=glossary-tooltip title=コンテナのライフサイクルを定義、展開、管理するためのAPIとインターフェイスを公開するコンテナオーケストレーションレイヤーです。 data-toggle=tooltip data-placement=top href="/ja/docs/reference/glossary/?all=true#term-control-plane" target=_blank aria-label="control plane">control plane</a>コンポーネントです。クラウドコントロールマネージャーは、クラスターをクラウドプロバイダーAPIをリンクし、クラスタのみで相互作用するコンポーネントからクラウドプラットフォームで相互作用するコンポーネントを分離します。</p></p>
<p>Kubernetesと下のクラウドインフラストラクチャー間の相互運用ロジックを分離することで、cloud-controller-managerコンポーネントはクラウドプロバイダを主なKubernetesプロジェクトと比較し異なるペースで機能をリリース可能にします。</p>
<h2 id=背景>背景</h2>
<p>クラウドプロバイダーはKubernetesプロジェクトとは異なる速度で開発しリリースすることから、プロバイダー特有なコードを<code>cloud-controller-manager</code>バイナリから抽象化することで、クラウドベンダーはコアKubernetesコードから独立して発展することができます。</p>
<p>Kubernetesプロジェクトは、(クラウドプロバイダーの)独自実装を組み込めるGoインターフェースを備えたcloud-controller-managerのスケルトンコードを提供しています。これは、クラウドプロバイダーがKubernetesコアからパッケージをインポートすることでcloud-controller-managerを実装できることを意味します。各クラウドプロバイダーは利用可能なクラウドプロバイダーのグローバル変数を更新するために<code>cloudprovider.RegisterCloudProvider</code>を呼び出し、独自のコードを登録します。</p>
<h2 id=開発>開発</h2>
<h3 id=kubernetesには登録されていない独自クラウドプロバイダー>Kubernetesには登録されていない独自クラウドプロバイダー</h3>
<p>Kubernetesには登録されていない独自のクラウドプロバイダーのクラウドコントローラーマネージャーを構築するには、</p>
<ol>
<li><a href=https://github.com/kubernetes/cloud-provider/blob/master/cloud.go>cloudprovider.Interface</a>を満たす go パッケージを実装します。</li>
<li>Kubernetesのコアにある<a href=https://github.com/kubernetes/kubernetes/blob/master/cmd/cloud-controller-manager/controller-manager.go>cloud-controller-managerの<code>main.go</code></a>をあなたの<code>main.go</code>のテンプレートとして利用します。上で述べたように、唯一の違いはインポートされるクラウドパッケージのみです。</li>
<li>クラウドパッケージを <code>main.go</code> にインポートし、パッケージに <a href=https://github.com/kubernetes/cloud-provider/blob/master/plugins.go><code>cloudprovider.RegisterCloudProvider</code></a> を実行するための <code>init</code> ブロックがあることを確認します。</li>
</ol>
<p>多くのクラウドプロバイダーはオープンソースとしてコントローラーマネージャーのコードを公開しています。新たにcloud-controller-managerをスクラッチから開発する際には、既存のKubernetesには登録されていない独自クラウドプロバイダーのコントローラーマネージャーを開始地点とすることができます。</p>
<h3 id=kubernetesに登録されているクラウドプロバイダー>Kubernetesに登録されているクラウドプロバイダー</h3>
<p>Kubernetesに登録されているクラウドプロバイダーであれば、<a class=glossary-tooltip title=Podのコピーがクラスター内の一連のNodeに渡って実行されることを保証します。 data-toggle=tooltip data-placement=top href=/docs/concepts/workloads/controllers/daemonset target=_blank aria-label=DaemonSet>DaemonSet</a>を使ってあなたのクラスターで動かすことができます。詳細については<a href=/ja/docs/tasks/administer-cluster/running-cloud-controller/>Kubernetesクラウドコントローラーマネージャー</a>を参照してください。</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-e1afcdac8d5e8458274b3c481c5ebcda>9 - サービスディスカバリーにCoreDNSを使用する</h1>
<p>このページでは、CoreDNSのアップグレードプロセスと、kube-dnsの代わりにCoreDNSをインストールする方法を説明します。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
作業するKubernetesサーバーは次のバージョン以降のものである必要があります: v1.9.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<h2 id=about-coredns>CoreDNSについて</h2>
<p><a href=https://coredns.io>CoreDNS</a>は、KubernetesクラスターDNSとして稼働させることができる柔軟で拡張可能なDNSサーバーです。Kubernetesと同様に、CoreDNSプロジェクトは<a class=glossary-tooltip title="Cloud Native Computing Foundation" data-toggle=tooltip data-placement=top href=https://cncf.io/ target=_blank aria-label=CNCF>CNCF</a>によってホストされています。</p>
<p>既存のデプロイでkube-dnsを置き換えるか、クラスターのデプロイとアップグレードを代行してくれるkubeadmのようなツールを使用することで、クラスターでkube-dnsの代わりにCoreDNSを使用することができます。</p>
<h2 id=installing-coredns>CoreDNSのインストール</h2>
<p>kube-dnsの手動デプロイや置き換えについては、<a href=https://github.com/coredns/deployment/tree/master/kubernetes>CoreDNS GitHub project</a>のドキュメントを参照してください。</p>
<h2 id=migrating-to-coredns>CoreDNSへの移行</h2>
<h3 id=upgrading-an-existing-cluster-with-kubeadm>kubeadmを使用した既存のクラスターのアップグレード</h3>
<p>Kubernetesバージョン1.10以降では、<code>kube-dns</code>を使用しているクラスターを<code>kubeadm</code>を使用してアップグレードするときに、CoreDNSに移行することもできます。この場合、<code>kubeadm</code>は、<code>kube-dns</code> ConfigMapをベースにしてCoreDNS設定("Corefile")を生成し、フェデレーション、スタブドメイン、および上流のネームサーバーの設定を保持します。</p>
<p>kube-dnsからCoreDNSに移行する場合は、アップグレード時に必ず<code>CoreDNS</code>フィーチャーゲートを<code>true</code>に設定してください。たとえば、<code>v1.11.0</code>のアップグレードは次のようになります:</p>
<pre><code>kubeadm upgrade apply v1.11.0 --feature-gates=CoreDNS=true
</code></pre><p>Kubernetesバージョン1.13以降では、<code>CoreDNS</code>フィーチャーゲートが削除され、CoreDNSがデフォルトで使用されます。アップグレードしたクラスターでkube-dnsを使用する場合は、<a href=/docs/reference/setup-tools/kubeadm/kubeadm-init-phase#cmd-phase-addon>こちら</a>のガイドに従ってください。</p>
<p>1.11以前のバージョンでは、Corefileはアップグレード中に作成されたものによって<strong>上書き</strong>されます。<strong>カスタマイズしている場合は、既存のConfigMapを保存する必要があります。</strong> 新しいConfigMapが稼働したら、カスタマイズを再適用できます。</p>
<p>Kubernetesバージョン1.11以降でCoreDNSを実行している場合、アップグレード中、既存のCorefileは保持されます。</p>
<h3 id=installing-kube-dns-instead-of-coredns-with-kubeadm>kubeadmを使用してCoreDNSの代わりにkube-dnsをインストールする</h3>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> Kubernetes 1.11では、CoreDNSは一般利用可能(GA)にアップグレードされ、デフォルトでインストールされます。
</div>
<div class="alert alert-danger warning callout" role=alert>
<strong>警告:</strong> Kubernetes 1.18では、kubeadmでのkube-dns使用は非推奨となり、将来のバージョンでは削除されます。
</div>
<p>1.13以前のバージョンにkube-dnsをインストールするには、<code>CoreDNS</code>フィーチャーゲートの値を<code>false</code>に設定します:</p>
<pre><code>kubeadm init --feature-gates=CoreDNS=false
</code></pre><p>バージョン1.13以降の場合は、<a href=/docs/reference/setup-tools/kubeadm/kubeadm-init-phase#cmd-phase-addon>こちら</a>に記載されているガイドに従ってください。</p>
<h2 id=upgrading-coredns>CoreDNSのアップグレード</h2>
<p>CoreDNSはv1.9以降のKubernetesで使用できます。Kubernetesに同梱されているCoreDNSのバージョンと、CoreDNSに加えられた変更は<a href=https://github.com/coredns/deployment/blob/master/kubernetes/CoreDNS-k8s_version.md>こちら</a>で確認できます。</p>
<p>CoreDNSだけをアップグレードしたい場合や、独自のカスタムイメージを使用したい場合は、CoreDNSを手動でアップグレードすることができます。スムーズなアップグレードのために役立つ<a href=https://github.com/coredns/deployment/blob/master/kubernetes/Upgrading_CoreDNS.md>ガイドラインとウォークスルー</a>が用意されています。</p>
<h2 id=tuning-coredns>CoreDNSのチューニング</h2>
<p>リソース使用率が問題になる場合は、CoreDNSの設定を調整すると役立つ場合があります。詳細は、<a href=https://github.com/coredns/deployment/blob/master/kubernetes/Scaling_CoreDNS.md>CoreDNSのスケーリングに関するドキュメント</a>を参照してください。</p>
<h2 id=次の項目>次の項目</h2>
<p><a href=https://coredns.io>CoreDNS</a>は、<code>Corefile</code>を変更することで、kube-dnsよりも多くのユースケースをサポートするように設定することができます。詳細は<a href=https://coredns.io/2017/05/08/custom-dns-entries-for-kubernetes/>CoreDNSサイト</a>を参照してください。</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-a3790dfb57271d13517e549dffa805b9>10 - ネットワークポリシーを宣言する</h1>
<p>このドキュメントでは、Pod同士の通信を制御するネットワークポリシーを定義するための、Kubernetesの<a href=/docs/concepts/services-networking/network-policies/>NetworkPolicy API</a>を使い始める手助けをします。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
作業するKubernetesサーバーは次のバージョン以降のものである必要があります: v1.8.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<p>ネットワークポリシーをサポートしているネットワークプロバイダーが設定済みであることを確認してください。さまざまなネットワークプロバイダーがNetworkPolicyをサポートしています。次に挙げるのは一例です。</p>
<ul>
<li><a href=/docs/tasks/administer-cluster/network-policy-provider/calico-network-policy/>Calico</a></li>
<li><a href=/docs/tasks/administer-cluster/network-policy-provider/cilium-network-policy/>Cilium</a></li>
<li><a href=/docs/tasks/administer-cluster/network-policy-provider/kube-router-network-policy/>Kube-router</a></li>
<li><a href=/docs/tasks/administer-cluster/network-policy-provider/romana-network-policy/>Romana</a></li>
<li><a href=/docs/tasks/administer-cluster/network-policy-provider/weave-network-policy/>Weave Net</a></li>
</ul>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> 上記のリストは製品名のアルファベット順にソートされていて、推奨順や好ましい順にソートされているわけではありません。このページの例は、Kubernetesクラスターでこれらのどのプロバイダーを使用していても有効です。
</div>
<h2 id=nginx-deploymentを作成してservice経由で公開する><code>nginx</code> Deploymentを作成してService経由で公開する</h2>
<p>Kubernetesのネットワークポリシーの仕組みを理解するために、まずは<code>nginx</code> Deploymentを作成することから始めましょう。</p>
<pre><code class=language-console data-lang=console>kubectl create deployment nginx --image=nginx
</code></pre><pre><code class=language-none data-lang=none>deployment.apps/nginx created
</code></pre><p><code>nginx</code>という名前のService経由でDeploymentを公開します。</p>
<pre><code class=language-console data-lang=console>kubectl expose deployment nginx --port=80
</code></pre><pre><code class=language-none data-lang=none>service/nginx exposed
</code></pre><p>上記のコマンドを実行すると、nginx Podを持つDeploymentが作成され、そのDeploymentが<code>nginx</code>という名前のService経由で公開されます。<code>nginx</code>のPodおよびDeploymentは<code>default</code>名前空間の中にあります。</p>
<pre><code class=language-console data-lang=console>kubectl get svc,pod
</code></pre><pre><code class=language-none data-lang=none>NAME                        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE
service/kubernetes          10.100.0.1    &lt;none&gt;        443/TCP    46m
service/nginx               10.100.0.16   &lt;none&gt;        80/TCP     33s

NAME                        READY         STATUS        RESTARTS   AGE
pod/nginx-701339712-e0qfq   1/1           Running       0          35s
</code></pre><h2 id=もう1つのpodからアクセスしてserviceを検証する>もう1つのPodからアクセスしてServiceを検証する</h2>
<p>これで、新しい<code>nginx</code>サービスに他のPodからアクセスできるようになったはずです。<code>default</code>名前空間内の他のPodから<code>nginx</code> Serviceにアクセスするために、busyboxコンテナを起動します。</p>
<pre><code class=language-console data-lang=console>kubectl run busybox --rm -ti --image=busybox -- /bin/sh
</code></pre><p>シェルの中で、次のコマンドを実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>wget --spider --timeout<span style=color:#666>=</span><span style=color:#666>1</span> nginx
</code></pre></div><pre><code class=language-none data-lang=none>Connecting to nginx (10.100.0.16:80)
remote file exists
</code></pre><h2 id=nginx-serviceへのアクセスを制限する><code>nginx</code> Serviceへのアクセスを制限する</h2>
<p><code>nginx</code> Serviceへのアクセスを制限するために、<code>access: true</code>というラベルが付いたPodだけがクエリできるようにします。次の内容でNetworkPolicyオブジェクトを作成してください。</p>
<div class=highlight>
<div class=copy-code-icon style=text-align:right>
<a href=https://raw.githubusercontent.com/kubernetes/website/main/content/ja/examples/service/networking/nginx-policy.yaml download=service/networking/nginx-policy.yaml><code>service/networking/nginx-policy.yaml</code>
</a>
<img src=/images/copycode.svg style=max-height:24px;cursor:pointer onclick="copyCode('service-networking-nginx-policy-yaml')" title="Copy service/networking/nginx-policy.yaml to clipboard">
</img>
</div>
<div class=includecode id=service-networking-nginx-policy-yaml>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>apiVersion</span>:<span style=color:#bbb> </span>networking.k8s.io/v1<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>kind</span>:<span style=color:#bbb> </span>NetworkPolicy<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>metadata</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>access-nginx<span style=color:#bbb>
</span><span style=color:#bbb></span><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>app</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>ingress</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>from</span>:<span style=color:#bbb>
</span><span style=color:#bbb>    </span>- <span style=color:green;font-weight:700>podSelector</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>matchLabels</span>:<span style=color:#bbb>
</span><span style=color:#bbb>          </span><span style=color:green;font-weight:700>access</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;true&#34;</span><span style=color:#bbb>
</span></code></pre></div>
</div>
</div>
<p>NetworkPolicyオブジェクトの名前は、有効な<a href=/ja/docs/concepts/overview/working-with-objects/names#dns-subdomain-names>DNSサブドメイン名</a>でなければなりません。</p>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> このNetworkPolicyには、ポリシーを適用するPodのグループを選択するための<code>podSelector</code>が含まれています。このポリシーは、ラベル<code>app=nginx</code>の付いたPodを選択していることがわかります。このラベルは、<code>nginx</code> Deployment内のPodに自動的に追加されたものです。空の<code>podSelector</code>は、その名前空間内のすべてのPodを選択します。
</div>
<h2 id=serviceにポリシーを割り当てる>Serviceにポリシーを割り当てる</h2>
<p>kubectlを使って、上記の<code>nginx-policy.yaml</code>ファイルからNetworkPolicyを作成します。</p>
<pre><code class=language-console data-lang=console>kubectl apply -f https://k8s.io/examples/service/networking/nginx-policy.yaml
</code></pre><pre><code class=language-none data-lang=none>networkpolicy.networking.k8s.io/access-nginx created
</code></pre><h2 id=accessラベルが定義されていない状態でserviceへのアクセスをテストする>accessラベルが定義されていない状態でServiceへのアクセスをテストする</h2>
<p><code>nginx</code> Serviceに正しいラベルが付いていないPodからアクセスを試してみると、リクエストがタイムアウトします。</p>
<pre><code class=language-console data-lang=console>kubectl run busybox --rm -ti --image=busybox -- /bin/sh
</code></pre><p>シェルの中で、次のコマンドを実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>wget --spider --timeout<span style=color:#666>=</span><span style=color:#666>1</span> nginx
</code></pre></div><pre><code class=language-none data-lang=none>Connecting to nginx (10.100.0.16:80)
wget: download timed out
</code></pre><h2 id=accessラベルを定義して再テストする>accessラベルを定義して再テストする</h2>
<p>正しいラベルが付いたPodを作成すると、リクエストが許可されるようになるのがわかります。</p>
<pre><code class=language-console data-lang=console>kubectl run busybox --rm -ti --labels=&quot;access=true&quot; --image=busybox -- /bin/sh
</code></pre><p>シェルの中で、次のコマンドを実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>wget --spider --timeout<span style=color:#666>=</span><span style=color:#666>1</span> nginx
</code></pre></div><pre><code class=language-none data-lang=none>Connecting to nginx (10.100.0.16:80)
remote file exists
</code></pre>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-8060aed5bf1172fa62199a4c306a4cd1>11 - ノードのトポロジー管理ポリシーを制御する</h1>
<div style=margin-top:10px;margin-bottom:10px>
<b>FEATURE STATE:</b> <code>Kubernetes v1.18 [beta]</code>
</div>
<p>近年、CPUやハードウェア・アクセラレーターの組み合わせによって、レイテンシーが致命的となる実行や高いスループットを求められる並列計算をサポートするシステムが増えています。このようなシステムには、通信、科学技術計算、機械学習、金融サービス、データ分析などの分野のワークロードが含まれます。このようなハイブリッドシステムは、高い性能の環境で構成されます。</p>
<p>最高のパフォーマンスを引き出すために、CPUの分離やメモリーおよびデバイスの位置に関する最適化が求められます。しかしながら、Kubernetesでは、これらの最適化は分断されたコンポーネントによって処理されます。</p>
<p><em>トポロジーマネージャー</em> はKubeletコンポーネントの1つで最適化の役割を担い、コンポーネント群を調和して機能させます。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
作業するKubernetesサーバーは次のバージョン以降のものである必要があります: v1.18.
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<h2 id=トポロジーマネージャーはどのように機能するか>トポロジーマネージャーはどのように機能するか</h2>
<p>トポロジーマネージャー導入前は、KubernetesにおいてCPUマネージャーやデバイスマネージャーはそれぞれ独立してリソースの割り当てを決定します。
これは、マルチソケットのシステムでは望ましくない割り当てとなり、パフォーマンスやレイテンシーが求められるアプリケーションは、この望ましくない割り当てに悩まされます。
この場合の望ましくない例として、CPUやデバイスが異なるNUMAノードに割り当てられ、それによりレイテンシー悪化を招くことが挙げられます。</p>
<p>トポロジーマネージャーはKubeletコンポーネントであり、信頼できる情報源として振舞います。それによって、他のKubeletコンポーネントはトポロジーに沿ったリソース割り当ての選択を行うことができます。</p>
<p>トポロジーマネージャーは <em>Hint Providers</em> と呼ばれるコンポーネントのインターフェースを提供し、トポロジー情報を送受信します。トポロジーマネージャーは、ノード単位のポリシー群を保持します。ポリシーについて以下で説明します。</p>
<p>トポロジーマネージャーは <em>Hint Providers</em> からトポロジー情報を受け取ります。トポロジー情報は、利用可能なNUMAノードと優先割り当て表示を示すビットマスクです。トポロジーマネージャーのポリシーは、提供されたヒントに対して一連の操作を行い、ポリシーに沿ってヒントをまとめて最適な結果を得ます。もし、望ましくないヒントが保存された場合、ヒントの優先フィールドがfalseに設定されます。現在のポリシーでは、最も狭い優先マスクが優先されます。</p>
<p>選択されたヒントはトポロジーマネージャーの一部として保存されます。設定されたポリシーにしたがい、選択されたヒントに基づいてノードがPodを許可したり、拒否することができます。
トポロジーマネージャーに保存されたヒントは、<em>Hint Providers</em> が使用しリソース割り当てを決定します。</p>
<h3 id=トポロジーマネージャーの機能を有効にする>トポロジーマネージャーの機能を有効にする</h3>
<p>トポロジーマネージャーをサポートするには、<code>TopologyManager</code> <a href=/ja/docs/reference/command-line-tools-reference/feature-gates/>フィーチャーゲート</a>を有効にする必要があります。Kubernetes 1.18ではデフォルトで有効です。</p>
<h2 id=トポロジーマネージャーのスコープとポリシー>トポロジーマネージャーのスコープとポリシー</h2>
<p>トポロジーマネージャは現在:</p>
<ul>
<li>全てのQoAクラスのPodを調整する</li>
<li>Hint Providerによって提供されたトポロジーヒントから、要求されたリソースを調整する</li>
</ul>
<p>これらの条件が合致した場合、トポロジーマネージャーは要求されたリソースを調整します。</p>
<p>この調整をどのように実行するかカスタマイズするために、トポロジーマネージャーは2つのノブを提供します: <code>スコープ</code> と<code>ポリシー</code>です。</p>
<p><code>スコープ</code>はリソースの配置を行う粒度を定義します(例:<code>pod</code>や<code>container</code>)。そして、<code>ポリシー</code>は調整を実行するための実戦略を定義します(<code>best-effort</code>, <code>restricted</code>, <code>single-numa-node</code>等)。</p>
<p>現在利用可能な<code>スコープ</code>と<code>ポリシー</code>の値について詳細は以下の通りです。</p>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> PodのSpecにある他の要求リソースとCPUリソースを調整するために、CPUマネージャーを有効にし、適切なCPUマネージャーのポリシーがノードに設定されるべきです。<a href=/docs/tasks/administer-cluster/cpu-management-policies/>CPU管理ポリシー</a>を参照してください。
</div>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> PodのSpecにある他の要求リソースとメモリー（およびhugepage）リソースを調整するために、メモリーマネージャーを有効にし、適切なメモリーマネージャーポリシーがノードに設定されるべきです。<a href=/docs/tasks/administer-cluster/memory-manager/>メモリーマネージャー</a> のドキュメントを確認してください。
</div>
<h3 id=トポロジーマネージャーのスコープ>トポロジーマネージャーのスコープ</h3>
<p>トポロジーマネージャーは、以下の複数の異なるスコープでリソースの調整を行う事が可能です:</p>
<ul>
<li><code>container</code> (デフォルト)</li>
<li><code>pod</code></li>
</ul>
<p>いずれのオプションも、<code>--topology-manager-scope</code>フラグによって、kubelet起動時に選択できます。</p>
<h3 id=containerスコープ>containerスコープ</h3>
<p><code>container</code>スコープはデフォルトで使用されます。</p>
<p>このスコープでは、トポロジーマネージャーは連続した複数のリソース調整を実行します。つまり、Pod内の各コンテナは、分離された配置計算がされます。言い換えると、このスコープでは、コンテナを特定のNUMAノードのセットにグループ化するという概念はありません。実際には、トポロジーマネージャーは各コンテナのNUMAノードへの配置を任意に実行します。</p>
<p>コンテナをグループ化するという概念は、以下のスコープで設定・実行されます。例えば、<code>pod</code>スコープが挙げられます。</p>
<h3 id=podスコープ>podスコープ</h3>
<p><code>pod</code>スコープを選択するには、コマンドラインで<code>--topology-manager-scope=pod</code>オプションを指定してkubeletを起動します。</p>
<p>このスコープでは、Pod内全てのコンテナを共通のNUMAノードのセットにグループ化することができます。トポロジーマネージャーはPodをまとめて1つとして扱い、ポッド全体（全てのコンテナ）を単一のNUMAノードまたはNUMAノードの共通セットのいずれかに割り当てようとします。以下の例は、さまざまな場面でトポロジーマネージャーが実行する調整を示します:</p>
<ul>
<li>全てのコンテナは、単一のNUMAノードに割り当てられます。</li>
<li>全てのコンテナは、共有されたNUMAノードのセットに割り当てられます。</li>
</ul>
<p>Pod全体に要求される特定のリソースの総量は<a href=/ja/docs/concepts/workloads/pods/init-containers/#resources>有効なリクエスト／リミット</a>の式に従って計算されるため、この総量の値は以下の最大値となります。</p>
<ul>
<li>全てのアプリケーションコンテナのリクエストの合計。</li>
<li>リソースに対するinitコンテナのリクエストの最大値。</li>
</ul>
<p><code>pod</code>スコープと<code>single-numa-node</code>トポロジーマネージャーポリシーを併用することは、レイテンシーが重要なワークロードやIPCを行う高スループットのアプリケーションに対して特に有効です。両方のオプションを組み合わせることで、Pod内の全てのコンテナを単一のNUMAノードに配置できます。そのため、PodのNUMA間通信によるオーバーヘッドを排除することができます。</p>
<p><code>single-numa-node</code>ポリシーの場合、可能な割り当ての中に適切なNUMAノードのセットが存在する場合にのみ、Podが許可されます。上の例をもう一度考えてみましょう:</p>
<ul>
<li>1つのNUMAノードのみを含むセット - Podが許可されます。</li>
<li>2つ以上のNUMAノードを含むセット - Podが拒否されます(1つのNUMAノードの代わりに、割り当てを満たすために2つ以上のNUMAノードが必要となるため)。</li>
</ul>
<p>要約すると、トポロジーマネージャーはまずNUMAノードのセットを計算し、それをトポロジーマネージャーのポリシーと照合し、Podの拒否または許可を検証します。</p>
<h3 id=トポロジーマネージャーのポリシー>トポロジーマネージャーのポリシー</h3>
<p>トポロジーマネージャーは4つの調整ポリシーをサポートします。<code>--topology-manager-policy</code>というKubeletフラグを通してポリシーを設定できます。
4つのサポートされるポリシーがあります:</p>
<ul>
<li><code>none</code> (デフォルト)</li>
<li><code>best-effort</code></li>
<li><code>restricted</code></li>
<li><code>single-numa-node</code></li>
</ul>
<div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> トポロジーマネージャーが <strong>pod</strong> スコープで設定された場合、コンテナはポリシーによって、Pod全体の要求として反映します。
したがって、Podの各コンテナは <strong>同じ</strong> トポロジー調整と同じ結果となります。
</div>
<h3 id=policy-none>none ポリシー</h3>
<p>これはデフォルトのポリシーで、トポロジーの調整を実行しません。</p>
<h3 id=policy-best-effort>best-effort ポリシー</h3>
<p>Pod内の各コンテナに対して、<code>best-effort</code> トポロジー管理ポリシーが設定されたkubeletは、各Hint Providerを呼び出してそれらのリソースの可用性を検出します。
トポロジーマネージャーはこの情報を使用し、そのコンテナの推奨されるNUMAノードのアフィニティーを保存します。アフィニティーが優先されない場合、トポロジーマネージャーはこれを保存し、Podをノードに許可します。</p>
<p><em>Hint Providers</em> はこの情報を使ってリソースの割り当てを決定します。</p>
<h3 id=policy-restricted>restricted ポリシー</h3>
<p>Pod内の各コンテナに対して、<code>restricted</code> トポロジー管理ポリシーが設定されたkubeletは各Hint Providerを呼び出してそれらのリソースの可用性を検出します。
トポロジーマネージャーはこの情報を使用し、そのコンテナの推奨されるNUMAノードのアフィニティーを保存します。アフィニティーが優先されない場合、トポロジーマネージャーはPodをそのノードに割り当てることを拒否します。この結果、PodはPodの受付失敗となり<code>Terminated</code> 状態になります。</p>
<p>Podが一度<code>Terminated</code>状態になると、KubernetesスケジューラーはPodの再スケジューリングを試み <strong>ません</strong> 。Podの再デプロイをするためには、ReplicasetかDeploymenを使用してください。<code>Topology Affinity</code>エラーとなったpodを再デプロイするために、外部のコントロールループを実行することも可能です。</p>
<p>Podが許可されれば、 <em>Hint Providers</em> はこの情報を使ってリソースの割り当てを決定します。</p>
<h3 id=policy-single-numa-node>single-numa-node ポリシー</h3>
<p>Pod内の各コンテナに対して、<code>single-numa-node</code>トポロジー管理ポリシーが設定されたkubeletは各Hint Prociderを呼び出してそれらのリソースの可用性を検出します。
トポロジーマネージャーはこの情報を使用し、単一のNUMAノードアフィニティが可能かどうか決定します。
可能な場合、トポロジーマネージャーは、この情報を保存し、<em>Hint Providers</em> はこの情報を使ってリソースの割り当てを決定します。
不可能な場合、トポロジーマネージャーは、Podをそのノードに割り当てることを拒否します。この結果、Pod は Pod の受付失敗となり<code>Terminated</code>状態になります。</p>
<p>Podが一度<code>Terminated</code>状態になると、KubernetesスケジューラーはPodの再スケジューリングを試み<strong>ません</strong>。Podの再デプロイをするためには、ReplicasetかDeploymentを使用してください。<code>Topology Affinity</code>エラーとなったpodを再デプロイするために、外部のコントロールループを実行することも可能です。</p>
<h3 id=podとトポロジー管理ポリシーの関係>Podとトポロジー管理ポリシーの関係</h3>
<p>以下のようなpodのSpecで定義されるコンテナを考えます:</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span></code></pre></div><p><code>requests</code>も<code>limits</code>も定義されていないため、このPodは<code>BestEffort</code>QoSクラスで実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;100Mi&#34;</span><span style=color:#bbb>
</span></code></pre></div><p>requestsがlimitsより小さい値のため、このPodは<code>Burstable</code>QoSクラスで実行します。</p>
<p>選択されたポリシーが<code>none</code>以外の場合、トポロジーマネージャーは、これらのPodのSpecを考慮します。トポロジーマネージャーは、Hint Providersからトポロジーヒントを取得します。CPUマネージャーポリシーが<code>static</code>の場合、デフォルトのトポロジーヒントを返却します。これらのPodは明示的にCPUリソースを要求していないからです。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;2&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></code></pre></div><p>整数値でCPUリクエストを指定されたこのPodは、<code>requests</code>が<code>limits</code>が同じ値のため、<code>Guaranteed</code>QoSクラスで実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;300m&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;200Mi&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;300m&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/device</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></code></pre></div><p>CPUの一部をリクエストで指定されたこのPodは、<code>requests</code>が<code>limits</code>が同じ値のため、<code>Guaranteed</code>QoSクラスで実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>spec</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span><span style=color:green;font-weight:700>containers</span>:<span style=color:#bbb>
</span><span style=color:#bbb>  </span>- <span style=color:green;font-weight:700>name</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>image</span>:<span style=color:#bbb> </span>nginx<span style=color:#bbb>
</span><span style=color:#bbb>    </span><span style=color:green;font-weight:700>resources</span>:<span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>limits</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceA</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceB</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>      </span><span style=color:green;font-weight:700>requests</span>:<span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceA</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span><span style=color:#bbb>        </span><span style=color:green;font-weight:700>example.com/deviceB</span>:<span style=color:#bbb> </span><span style=color:#b44>&#34;1&#34;</span><span style=color:#bbb>
</span></code></pre></div><p>CPUもメモリもリクエスト値がないため、このPodは <code>BestEffort</code> QoSクラスで実行します。</p>
<p>トポロジーマネージャーは、上記Podを考慮します。トポロジーマネージャーは、Hint ProvidersとなるCPUマネージャーとデバイスマネージャーに問い合わせ、トポロジーヒントを取得します。</p>
<p>整数値でCPU要求を指定された<code>Guaranteed</code>QoSクラスのPodの場合、<code>static</code>が設定されたCPUマネージャーポリシーは、排他的なCPUに関するトポロジーヒントを返却し、デバイスマネージャーは要求されたデバイスのヒントを返します。</p>
<p>CPUの一部を要求を指定された<code>Guaranteed</code>QoSクラスのPodの場合、排他的ではないCPU要求のため<code>static</code>が設定されたCPUマネージャーポリシーはデフォルトのトポロジーヒントを返却します。デバイスマネージャーは要求されたデバイスのヒントを返します。</p>
<p>上記の<code>Guaranteed</code>QoSクラスのPodに関する2ケースでは、<code>none</code>で設定されたCPUマネージャーポリシーは、デフォルトのトポロジーヒントを返却します。</p>
<p><code>BestEffort</code>QoSクラスのPodの場合、<code>static</code>が設定されたCPUマネージャーポリシーは、CPUの要求がないためデフォルトのトポロジーヒントを返却します。デバイスマネージャーは要求されたデバイスごとのヒントを返します。</p>
<p>トポロジーマネージャーはこの情報を使用してPodに最適なヒントを計算し保存します。保存されたヒントは Hint Providersが使用しリソースを割り当てます。</p>
<h3 id=既知の制限>既知の制限</h3>
<ol>
<li>
<p>トポロジーマネージャーが許容するNUMAノードの最大値は8です。8より多いNUMAノードでは、可能なNUMAアフィニティを列挙しヒントを生成する際に、生成する状態数が爆発的に増加します。</p>
</li>
<li>
<p>スケジューラーはトポロジーを意識しません。そのため、ノードにスケジュールされた後に実行に失敗する可能性があります。</p>
</li>
</ol>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-a8f6511197efcd7d0db80ade49620f9d>12 - 拡張リソースをNodeにアドバタイズする</h1>
<p>このページでは、Nodeに対して拡張リソースを指定する方法を説明します。拡張リソースを利用すると、Kubernetesにとって未知のノードレベルのリソースをクラスター管理者がアドバタイズできるようになります。</p>
<h2 id=始める前に>始める前に</h2>
<p><p>Kubernetesクラスターが必要、かつそのクラスターと通信するためにkubectlコマンドラインツールが設定されている必要があります。
このチュートリアルは、コントロールプレーンのホストとして動作していない少なくとも2つのノードを持つクラスターで実行することをおすすめします。
まだクラスターがない場合、<a href=https://minikube.sigs.k8s.io/docs/tutorials/multi_node/>minikube</a>を使って作成するか、
以下のいずれかのKubernetesプレイグラウンドも使用できます:</p>
<ul>
<li><a href=https://www.katacoda.com/courses/kubernetes/playground>Katacoda</a></li>
<li><a href=http://labs.play-with-k8s.com/>Play with Kubernetes</a></li>
</ul>
バージョンを確認するには次のコマンドを実行してください: <code>kubectl version</code>.
</p>
<h2 id=nodeの名前を取得する>Nodeの名前を取得する</h2>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl get nodes
</code></pre></div><p>この練習で使いたいNodeを1つ選んでください。</p>
<h2 id=nodeの1つで新しい拡張リソースをアドバタイズする>Nodeの1つで新しい拡張リソースをアドバタイズする</h2>
<p>Node上の新しい拡張リソースをアドバタイズするには、HTTPのPATCHリクエストをKubernetes APIサーバーに送ります。たとえば、Nodeの1つに4つのドングルが接続されているとします。以下に、4つのドングルリソースをNodeにアドバタイズするPATCHリクエストの例を示します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>PATCH /api/v1/nodes/&lt;選択したNodeの名前&gt;/status HTTP/1.1
Accept: application/json
Content-Type: application/json-patch+json
Host: k8s-master:8080

<span style=color:#666>[</span>
  <span style=color:#666>{</span>
    <span style=color:#b44>&#34;op&#34;</span>: <span style=color:#b44>&#34;add&#34;</span>,
    <span style=color:#b44>&#34;path&#34;</span>: <span style=color:#b44>&#34;/status/capacity/example.com~1dongle&#34;</span>,
    <span style=color:#b44>&#34;value&#34;</span>: <span style=color:#b44>&#34;4&#34;</span>
  <span style=color:#666>}</span>
<span style=color:#666>]</span>
</code></pre></div><p>Kubernetesは、ドングルとは何かも、ドングルが何に利用できるのかを知る必要もないことに注意してください。上のPATCHリクエストは、ただNodeが4つのドングルと呼ばれるものを持っているとKubernetesに教えているだけです。</p>
<p>Kubernetes APIサーバーに簡単にリクエストを送れるように、プロキシーを実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl proxy
</code></pre></div><p>もう1つのコマンドウィンドウを開き、HTTPのPATCHリクエストを送ります。<code>&lt;選択したNodeの名前></code>の部分は、選択したNodeの名前に置き換えてください。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl --header <span style=color:#b44>&#34;Content-Type: application/json-patch+json&#34;</span> <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--request PATCH <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--data <span style=color:#b44>&#39;[{&#34;op&#34;: &#34;add&#34;, &#34;path&#34;: &#34;/status/capacity/example.com~1dongle&#34;, &#34;value&#34;: &#34;4&#34;}]&#39;</span> <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>http://localhost:8001/api/v1/nodes/&lt;選択したNodeの名前&gt;/status
</code></pre></div><div class="alert alert-info note callout" role=alert>
<strong>備考:</strong> 上のリクエストにある<code>~1</code>は、PATCHのパスにおける<code>/</code>という文字をエンコーディングしたものです。JSON-Patch内のoperationのpathはJSON-Pointerとして解釈されます。詳細については、<a href=https://tools.ietf.org/html/rfc6901>IETF RFC 6901</a>のsection 3を読んでください。
</div>
<p>出力には、Nodeがキャパシティー4のdongleを持っていることが示されます。</p>
<pre><code>&quot;capacity&quot;: {
  &quot;cpu&quot;: &quot;2&quot;,
  &quot;memory&quot;: &quot;2049008Ki&quot;,
  &quot;example.com/dongle&quot;: &quot;4&quot;,
</code></pre><p>Nodeの説明を確認します。</p>
<pre><code>kubectl describe node &lt;選択したNodeの名前&gt;
</code></pre><p>出力には、再びdongleリソースが表示されます。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>Capacity</span>:<span style=color:#bbb>
</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>cpu</span>:<span style=color:#bbb>  </span><span style=color:#666>2</span><span style=color:#bbb>
</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>memory</span>:<span style=color:#bbb>  </span>2049008Ki<span style=color:#bbb>
</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>example.com/dongle</span>:<span style=color:#bbb>  </span><span style=color:#666>4</span><span style=color:#bbb>
</span></code></pre></div><p>これで、アプリケーション開発者は特定の数のdongleをリクエストするPodを作成できるようになりました。詳しくは、<a href=/docs/tasks/configure-pod-container/extended-resource/>拡張リソースをコンテナに割り当てる</a>を読んでください。</p>
<h2 id=議論>議論</h2>
<p>拡張リソースは、メモリやCPUリソースと同様のものです。たとえば、Nodeが持っている特定の量のメモリやCPUがNode上で動作している他のすべてのコンポーネントと共有されるのと同様に、Nodeが搭載している特定の数のdongleが他のすべてのコンポーネントと共有されます。そして、アプリケーション開発者が特定の量のメモリとCPUをリクエストするPodを作成できるのと同様に、Nodeが搭載している特定の数のdongleをリクエストするPodが作成できます。</p>
<p>拡張リソースはKubernetesには詳細を意図的に公開しないため、Kubernetesは拡張リソースの実体をまったく知りません。Kubernetesが知っているのは、Nodeが特定の数の拡張リソースを持っているということだけです。拡張リソースは整数値でアドバタイズしなければなりません。たとえば、Nodeは4つのdongleをアドバタイズできますが、4.5のdongleというのはアドバタイズできません。</p>
<h3 id=storageの例>Storageの例</h3>
<p>Nodeに800GiBの特殊なディスクストレージがあるとします。この特殊なストレージの名前、たとえばexample.com/special-storageという名前の拡張リソースが作れます。そして、そのなかの一定のサイズ、たとえば100GiBのチャンクをアドバタイズできます。この場合、Nodeはexample.com/special-storageという種類のキャパシティ8のリソースを持っているとアドバタイズします。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>Capacity</span>:<span style=color:#bbb>
</span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>example.com/special-storage</span>:<span style=color:#bbb> </span><span style=color:#666>8</span><span style=color:#bbb>
</span></code></pre></div><p>特殊なストレージに任意のサイズのリクエストを許可したい場合、特殊なストレージを1バイトのサイズのチャンクでアドバタイズできます。その場合、example.com/special-storageという種類の800Giのリソースとしてアドバタイズします。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=color:green;font-weight:700>Capacity</span>:<span style=color:#bbb>
</span><span style=color:#bbb> </span>...<span style=color:#bbb>
</span><span style=color:#bbb> </span><span style=color:green;font-weight:700>example.com/special-storage</span>:<span style=color:#bbb>  </span>800Gi<span style=color:#bbb>
</span></code></pre></div><p>すると、コンテナは好きなバイト数の特殊なストレージを最大800Giまでリクエストできるようになります。</p>
<h2 id=クリーンアップ>クリーンアップ</h2>
<p>以下に、dongleのアドバタイズをNodeから削除するPATCHリクエストを示します。</p>
<pre><code>PATCH /api/v1/nodes/&lt;選択したNodeの名前&gt;/status HTTP/1.1
Accept: application/json
Content-Type: application/json-patch+json
Host: k8s-master:8080

[
  {
    &quot;op&quot;: &quot;remove&quot;,
    &quot;path&quot;: &quot;/status/capacity/example.com~1dongle&quot;,
  }
]
</code></pre><p>Kubernetes APIサーバーに簡単にリクエストを送れるように、プロキシーを実行します。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>kubectl proxy
</code></pre></div><p>もう1つのコマンドウィンドウで、HTTPのPATCHリクエストを送ります。<code>&lt;選択したNodeの名前></code>の部分は、選択したNodeの名前に置き換えてください。</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>curl --header <span style=color:#b44>&#34;Content-Type: application/json-patch+json&#34;</span> <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--request PATCH <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>--data <span style=color:#b44>&#39;[{&#34;op&#34;: &#34;remove&#34;, &#34;path&#34;: &#34;/status/capacity/example.com~1dongle&#34;}]&#39;</span> <span style=color:#b62;font-weight:700>\
</span><span style=color:#b62;font-weight:700></span>http://localhost:8001/api/v1/nodes/&lt;選択したNodeの名前&gt;/status
</code></pre></div><p>dongleのアドバタイズが削除されたことを検証します。</p>
<pre><code>kubectl describe node &lt;選択したNodeの名前&gt; | grep dongle
</code></pre><p>(出力には何も表示されないはずです)</p>
<h2 id=次の項目>次の項目</h2>
<h3 id=アプリケーション開発者向け>アプリケーション開発者向け</h3>
<ul>
<li><a href=/ja/docs/tasks/configure-pod-container/extended-resource/>拡張リソースをコンテナに割り当てる</a></li>
</ul>
<h3 id=クラスター管理者向け>クラスター管理者向け</h3>
<ul>
<li><a href=/docs/tasks/administer-cluster/manage-resources/memory-constraint-namespace/>Namespaceに対してメモリの最小値と最大値の制約を設定する</a></li>
<li><a href=/docs/tasks/administer-cluster/manage-resources/cpu-constraint-namespace/>Namespaceに対してCPUの最小値と最大値の制約を設定する</a></li>
</ul>
</div>
</main>
</div>
</div>
<footer class=d-print-none>
<div class=footer__links>
<nav>
<a class=text-white href=/ja/docs/home/>ホーム</a>
<a class=text-white href=/ja/training/>トレーニング</a>
<a class=text-white href=/ja/partners/>パートナー</a>
<a class=text-white href=/ja/community/>コミュニティ</a>
<a class=text-white href=/ja/case-studies/>ケーススタディ</a>
</nav>
</div>
<div class=container-fluid>
<div class=row>
<div class="col-6 col-sm-2 text-xs-center order-sm-2">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list">
<a class=text-white target=_blank href=https://discuss.kubernetes.io>
<i class="fa fa-envelope"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter>
<a class=text-white target=_blank href=https://twitter.com/kubernetesio>
<i class="fab fa-twitter"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Calendar aria-label=Calendar>
<a class=text-white target=_blank href="https://calendar.google.com/calendar/embed?src=calendar%40kubernetes.io">
<i class="fas fa-calendar-alt"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Youtube aria-label=Youtube>
<a class=text-white target=_blank href=https://youtube.com/kubernetescommunity>
<i class="fab fa-youtube"></i>
</a>
</li>
</ul>
</div>
<div class="col-6 col-sm-2 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank href=https://github.com/kubernetes/kubernetes>
<i class="fab fa-github"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Slack aria-label=Slack>
<a class=text-white target=_blank href=https://slack.k8s.io>
<i class="fab fa-slack"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Contribute aria-label=Contribute>
<a class=text-white target=_blank href=https://git.k8s.io/community/contributors/guide>
<i class="fas fa-edit"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow">
<a class=text-white target=_blank href=https://stackoverflow.com/questions/tagged/kubernetes>
<i class="fab fa-stack-overflow"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-8 text-center order-sm-2">
<small class=text-white>&copy; 2023 The Kubernetes Authors | Documentation Distributed under <a href=https://git.k8s.io/website/LICENSE class=light-text>CC BY 4.0</a></small>
<br>
<small class=text-white>Copyright &copy; 2023 The Linux Foundation &reg;. All rights reserved. The Linux Foundation has registered trademarks and uses trademarks. For a list of trademarks of The Linux Foundation, please see our <a href=https://www.linuxfoundation.org/trademark-usage class=light-text>Trademark Usage page</a></small>
<br>
<small class=text-white>ICP license: 京ICP备17074266号-3</small>
</div>
</div>
</div>
</footer>
</div>
<script src=/js/popper-1.14.3.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script>
<script src=/js/bootstrap-4.3.1.min.js integrity=sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM crossorigin=anonymous></script>
<script src=/js/main.min.40616251a9b6e4b689e7769be0340661efa4d7ebb73f957404e963e135b4ed52.js integrity="sha256-QGFiUam25LaJ53ab4DQGYe+k1+u3P5V0BOlj4TW07VI=" crossorigin=anonymous></script>
</body>
</html>